{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "ep9kGml4s5Qg",
        "izeQ2YeBh7ap",
        "J_1Mh_volESL",
        "X2GZ0GX_ojnd",
        "LUBpVmRZhXsl",
        "U85NSfZxsBi6"
      ],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JzIiMqPGhHcF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5f0edbf-4701-4e0b-a4ad-4a0696cf3f2d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n",
            "/gdrive/My Drive/ANNDL/Challenge1\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive/My Drive/ANNDL/Challenge1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ep9kGml4s5Qg"
      },
      "source": [
        "# Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0kau6etYswEP"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "seed = 42\n",
        "\n",
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "os.environ['MPLCONFIGDIR'] = os.getcwd()+'/configs/'\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "warnings.simplefilter(action='ignore', category=Warning)\n",
        "\n",
        "import numpy as np\n",
        "np.random.seed(seed)\n",
        "\n",
        "import logging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MxhtIYjys1Ju",
        "outputId": "93e79f5a-9184-4532-896c-f2379c115898"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.14.0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras as tfk\n",
        "from tensorflow.keras import layers as tfkl\n",
        "tf.autograph.set_verbosity(0)\n",
        "tf.get_logger().setLevel(logging.ERROR)\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
        "tf.random.set_seed(seed)\n",
        "tf.compat.v1.set_random_seed(seed)\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uk9ADBOrs2kW"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "from tensorflow.keras.applications.mobilenet import preprocess_input\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
        "import seaborn as sns\n",
        "from collections import Counter\n",
        "\n",
        "import sklearn.model_selection as sklms\n",
        "import sklearn.metrics as sklm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Dataset"
      ],
      "metadata": {
        "id": "izeQ2YeBh7ap"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lo5HW7G-Iud3"
      },
      "outputs": [],
      "source": [
        "# Loading the data and dividing between data and labels\n",
        "data = np.load('public_data.npz', allow_pickle=True)\n",
        "\n",
        "x_tv = data['data']\n",
        "y_tv = data['labels']\n",
        "\n",
        "# Removing the outliers\n",
        "# Identify the first image of each outlier\n",
        "shrek = x_tv[58]\n",
        "troll = x_tv[412]\n",
        "\n",
        "# Looking for all the outliers in the dataset\n",
        "arrayShrek = []\n",
        "arrayTroll = []\n",
        "for i in range(len(x_tv)):\n",
        "    if (x_tv[i] == shrek).all():\n",
        "        arrayShrek = arrayShrek + [i]\n",
        "    elif (x_tv[i] == troll).all():\n",
        "        arrayTroll = arrayTroll + [i]\n",
        "\n",
        "deleteArray = arrayShrek + arrayTroll\n",
        "\n",
        "# Removing the outlier from the data and labels\n",
        "x_tv = np.delete(x_tv, deleteArray, axis=0)\n",
        "y_tv = np.delete(y_tv, deleteArray, axis=0)\n",
        "\n",
        "# Removing the duplicates images\n",
        "# Find all the duplicates\n",
        "duplicates = []\n",
        "for i in range(len(x_tv)):\n",
        "    for j in range(i+1, len(x_tv)):\n",
        "        if (x_tv[i] == x_tv[j]).all():\n",
        "           duplicates = duplicates + [j]\n",
        "\n",
        "# Delete the duplicates from the data and labels\n",
        "x_tv = np.delete(x_tv, duplicates, axis=0)\n",
        "y_tv = np.delete(y_tv, duplicates, axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_tv = np.array([0 if x == 'healthy' else 1 for x in y_tv])\n",
        "# Compute the class weights to understand if oversampling has balanced the classes\n",
        "itemCt = Counter(y_tv)\n",
        "maxCt = float(max(itemCt.values()))\n",
        "class_weights = {clsID : maxCt/numImg for clsID, numImg in itemCt.items()}"
      ],
      "metadata": {
        "id": "WIftMFo0wiBH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the dataset into training, validation and test\n",
        "X_train_val, X_test, y_train_val, y_test = train_test_split(x_tv, y_tv, random_state=seed, test_size=200, stratify=y_tv)\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, random_state=seed, test_size=0.20, stratify = y_train_val)"
      ],
      "metadata": {
        "id": "ojJ-lkg4GCqs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Oversampling the dataset to reach an equal number of samples for each class\n",
        "# Count the number of images that needs to be added to the unhealthy class\n",
        "healthy = 0\n",
        "for i in range(len(x_tv)):\n",
        "    if y_tv[i] == 'healthy':\n",
        "        healthy = healthy + 1\n",
        "\n",
        "diff = healthy - (len(x_tv) - healthy)"
      ],
      "metadata": {
        "id": "hBK2qGLb1zgD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Oversampling the dataset to reach an equal number of samples for each class\n",
        "# Count the number of images that needs to be added to the unhealthy class\n",
        "countOS = 0\n",
        "newSamples=[]\n",
        "number_of_os = np.count_nonzero(y_train == 0) - np.count_nonzero(y_train == 1)\n",
        "\n",
        "for i in range(len(X_train)):\n",
        "    if(y_train[i] == 1 and countOS < number_of_os):\n",
        "        if(i%3 == 0):\n",
        "            newEl = np.rot90(X_train[i])\n",
        "        elif(i%3 == 1):\n",
        "            newEl = np.fliplr(X_train[i])\n",
        "        else:\n",
        "            newEl = np.flipud(X_train[i])\n",
        "        newSamples.append(newEl)\n",
        "        countOS = countOS +1\n",
        "\n",
        "# Add new samples\n",
        "newSamples = np.array(newSamples)\n",
        "X_train = np.concatenate((X_train, newSamples), axis=0)\n",
        "ones = np.array([1 for i in range(number_of_os)])\n",
        "y_train = np.concatenate((y_train, ones), axis=None)\n",
        "\n",
        "# Convert labels to categorical\n",
        "y_train = tfk.utils.to_categorical(y_train,2)\n",
        "y_val = tfk.utils.to_categorical(y_val,2)\n",
        "y_test = tfk.utils.to_categorical(y_test,2)\n",
        "\n",
        "input_shape = X_train.shape[1:]\n",
        "output_shape = y_train.shape[1:]\n",
        "\n",
        "print(\"input shape: \", input_shape)\n",
        "print(\"output shape: \", output_shape)"
      ],
      "metadata": {
        "id": "oZtoEOlNjJSE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2aa90c51-8497-44ca-90e6-8589f96f327f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input shape:  (96, 96, 3)\n",
            "output shape:  (2,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mixup"
      ],
      "metadata": {
        "id": "j60MCRdS1wD7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mixup implementation from https://keras.io/examples/vision/mixup/\n",
        "AUTO = tf.data.AUTOTUNE\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 10\n",
        "\n",
        "train_ds_one = (\n",
        "    tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
        "    .shuffle(BATCH_SIZE * 100)\n",
        "    .batch(BATCH_SIZE)\n",
        ")\n",
        "train_ds_two = (\n",
        "    tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
        "    .shuffle(BATCH_SIZE * 100)\n",
        "    .batch(BATCH_SIZE)\n",
        ")\n",
        "# Because we will be mixing up the images and their corresponding labels, we will be\n",
        "# combining two shuffled datasets from the same training data.\n",
        "train_ds = tf.data.Dataset.zip((train_ds_one, train_ds_two))"
      ],
      "metadata": {
        "id": "7n-FpzF8v5aM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sample_beta_distribution(size, concentration_0=0.2, concentration_1=0.2):\n",
        "    gamma_1_sample = tf.random.gamma(shape=[size], alpha=concentration_1)\n",
        "    gamma_2_sample = tf.random.gamma(shape=[size], alpha=concentration_0)\n",
        "    return gamma_1_sample / (gamma_1_sample + gamma_2_sample)\n",
        "\n",
        "\n",
        "def mix_up(ds_one, ds_two, alpha=0.2):\n",
        "    # Unpack two datasets\n",
        "    images_one, labels_one = ds_one\n",
        "    images_two, labels_two = ds_two\n",
        "    batch_size = tf.shape(images_one)[0]\n",
        "\n",
        "    # Sample lambda and reshape it to do the mixup\n",
        "    l = sample_beta_distribution(batch_size, alpha, alpha)\n",
        "    x_l = tf.reshape(l, (batch_size, 1, 1, 1))\n",
        "    y_l = tf.reshape(l, (batch_size, 1))\n",
        "\n",
        "    # Perform mixup on both images and labels by combining a pair of images/labels\n",
        "    # (one from each dataset) into one image/label\n",
        "    images = images_one * x_l + images_two * (1 - x_l)\n",
        "    labels = labels_one * y_l + labels_two * (1 - y_l)\n",
        "    return (images, labels)"
      ],
      "metadata": {
        "id": "moTNSKQZxtVR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#this is the train set to be used with mixup, during training it should be used in place of x and y\n",
        "train_ds_mu = train_ds.map(\n",
        "    lambda ds_one, ds_two: mix_up(ds_one, ds_two, alpha=0.2), num_parallel_calls=AUTO\n",
        ")"
      ],
      "metadata": {
        "id": "7l-oS0av00Ft"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_1Mh_volESL"
      },
      "source": [
        "# First (Simple) Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AuhH43m7AbS4"
      },
      "outputs": [],
      "source": [
        "def inception_module(x,\n",
        "                     filters_1x1,\n",
        "                     filters_3x3_reduce,\n",
        "                     filters_3x3,\n",
        "                     filters_5x5_reduce,\n",
        "                     filters_5x5,\n",
        "                     filters_pool_proj,\n",
        "                     name=None):\n",
        "\n",
        "    conv_1x1 = tfkl.Conv2D(filters_1x1, (1, 1), padding='same', activation='relu', kernel_initializer=tfk.initializers.HeUniform(seed=seed))(x)\n",
        "\n",
        "    conv_3x3 = tfkl.Conv2D(filters_3x3_reduce, (1, 1), padding='same', activation='relu', kernel_initializer=tfk.initializers.HeUniform(seed=seed))(x)\n",
        "    conv_3x3 = tfkl.Conv2D(filters_3x3, (3, 3), padding='same', activation='relu', kernel_initializer=tfk.initializers.HeUniform(seed=seed))(conv_3x3)\n",
        "\n",
        "    conv_5x5 = tfkl.Conv2D(filters_5x5_reduce, (1, 1), padding='same', activation='relu', kernel_initializer=tfk.initializers.HeUniform(seed=seed))(x)\n",
        "    conv_5x5 = tfkl.Conv2D(filters_5x5, (5, 5), padding='same', activation='relu', kernel_initializer=tfk.initializers.HeUniform(seed=seed))(conv_5x5)\n",
        "\n",
        "    pool_proj = tfkl.MaxPooling2D((3, 3), strides=(1, 1), padding='same')(x)\n",
        "    pool_proj = tfkl.Conv2D(filters_pool_proj, (1, 1), padding='same', activation='relu', kernel_initializer=tfk.initializers.HeUniform(seed=seed))(pool_proj)\n",
        "\n",
        "    output = tfkl.Concatenate(axis=-1)([conv_1x1, conv_3x3, conv_5x5, pool_proj])\n",
        "\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model_with_augmentation(l2_lambda, input_shape=input_shape, output_shape=output_shape):\n",
        "    tf.random.set_seed(seed)\n",
        "    preprocessing = tf.keras.Sequential([\n",
        "        tfkl.RandomContrast(0.5),\n",
        "        tfkl.RandomTranslation(0.2,0.2),\n",
        "        tfkl.RandomFlip(\"horizontal_and_vertical\"),\n",
        "        tfkl.RandomRotation(1),\n",
        "        tfkl.RandomZoom(0.2),\n",
        "    ], name='preprocessing')\n",
        "\n",
        "    input_layer = tfkl.Input(shape=input_shape, name='Input')\n",
        "\n",
        "    preprocessing = preprocessing(input_layer)\n",
        "\n",
        "    x = tfkl.Conv2D(filters=32, kernel_size=3, padding='same', name='conv0')(preprocessing)\n",
        "    x = tfkl.ReLU(name='relu0')(x)\n",
        "    x = tfkl.MaxPooling2D(name='mp0')(x)\n",
        "\n",
        "    x = tfkl.Conv2D(filters=64, kernel_size=3, padding='same', name='conv1')(x)\n",
        "    x = tfkl.ReLU(name='relu1')(x)\n",
        "    x = tfkl.MaxPooling2D(name='mp1')(x)\n",
        "\n",
        "    x = inception_module(x,\n",
        "                      filters_1x1=64,\n",
        "                      filters_3x3_reduce=96,\n",
        "                      filters_3x3=128,\n",
        "                      filters_5x5_reduce=16,\n",
        "                      filters_5x5=32,\n",
        "                      filters_pool_proj=32,\n",
        "                      name='inception_1a')\n",
        "\n",
        "    x = inception_module(x,\n",
        "                      filters_1x1=128,\n",
        "                      filters_3x3_reduce=128,\n",
        "                      filters_3x3=192,\n",
        "                      filters_5x5_reduce=32,\n",
        "                      filters_5x5=96,\n",
        "                      filters_pool_proj=64,\n",
        "                      name='inception_1b')\n",
        "\n",
        "    x = tfkl.MaxPooling2D(name='mp2')(x)\n",
        "\n",
        "    y = x\n",
        "\n",
        "    x = inception_module(x,\n",
        "                     filters_1x1=160,\n",
        "                     filters_3x3_reduce=112,\n",
        "                     filters_3x3=224,\n",
        "                     filters_5x5_reduce=24,\n",
        "                     filters_5x5=64,\n",
        "                     filters_pool_proj=64,\n",
        "                     name='inception_2a')\n",
        "\n",
        "    x = inception_module(x,\n",
        "                     filters_1x1=128,\n",
        "                     filters_3x3_reduce=128,\n",
        "                     filters_3x3=192,\n",
        "                     filters_5x5_reduce=32,\n",
        "                     filters_5x5=96,\n",
        "                     filters_pool_proj=64,\n",
        "                     name='inception_2b')\n",
        "\n",
        "    x = tfkl.Add()([x, y])\n",
        "\n",
        "    y = x\n",
        "\n",
        "    x = inception_module(x,\n",
        "                      filters_1x1=192,\n",
        "                      filters_3x3_reduce=96,\n",
        "                      filters_3x3=208,\n",
        "                      filters_5x5_reduce=16,\n",
        "                      filters_5x5=48,\n",
        "                      filters_pool_proj=64,\n",
        "                      name='inception_3a')\n",
        "\n",
        "    x = inception_module(x,\n",
        "                     filters_1x1=256,\n",
        "                     filters_3x3_reduce=160,\n",
        "                     filters_3x3=320,\n",
        "                     filters_5x5_reduce=32,\n",
        "                     filters_5x5=128,\n",
        "                     filters_pool_proj=128,\n",
        "                     name='inception_3b')\n",
        "\n",
        "    x = inception_module(x,\n",
        "                     filters_1x1=128,\n",
        "                     filters_3x3_reduce=128,\n",
        "                     filters_3x3=192,\n",
        "                     filters_5x5_reduce=32,\n",
        "                     filters_5x5=96,\n",
        "                     filters_pool_proj=64,\n",
        "                     name='inception_3c')\n",
        "\n",
        "\n",
        "    x = tfkl.Add()([x, y])\n",
        "\n",
        "    x = tfkl.GlobalAveragePooling2D(name='gap')(x)\n",
        "\n",
        "    x = tfkl.Dense(units=256, activation='relu',name='classification1', kernel_regularizer=tf.keras.regularizers.l2(l2_lambda),\n",
        "                   kernel_initializer=tfk.initializers.HeUniform(seed=seed))(x)\n",
        "    x = tfkl.Dropout(0.5, seed=seed)(x)\n",
        "\n",
        "    x = tfkl.Dense(units=128, activation='relu',name='classification2', kernel_regularizer=tf.keras.regularizers.l2(l2_lambda),\n",
        "                   kernel_initializer=tfk.initializers.HeUniform(seed=seed))(x)\n",
        "    x = tfkl.Dropout(0.5, seed=seed)(x)\n",
        "\n",
        "    output_layer = tfkl.Dense(units=2, activation='softmax',name='Output')(x)\n",
        "\n",
        "    # Connect input and output through the Model class\n",
        "    model = tfk.Model(inputs=input_layer, outputs=output_layer, name='CNN')\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(loss=tfk.losses.BinaryCrossentropy(), optimizer=tfk.optimizers.Adam(), metrics=['accuracy'])\n",
        "\n",
        "    # Return the model\n",
        "    return model"
      ],
      "metadata": {
        "id": "GaHDel25kesI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tJZBd63IlESY"
      },
      "outputs": [],
      "source": [
        "model = build_model_with_augmentation()\n",
        "model.summary()\n",
        "tfk.utils.plot_model(model, expand_nested=True, show_shapes=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1RN4cFV1lESY"
      },
      "outputs": [],
      "source": [
        "lr_patience = 15\n",
        "lr_scheduler = tfk.callbacks.ReduceLROnPlateau(\n",
        "    monitor='val_accuracy',\n",
        "    patience=lr_patience,\n",
        "    factor=0.9,\n",
        "    mode='auto',\n",
        "    min_lr=1e-5\n",
        ")\n",
        "\n",
        "early_stopping = tfk.callbacks.EarlyStopping(monitor='val_accuracy', patience=30, restore_best_weights=True, mode='auto')\n",
        "\n",
        "callbacks = [\n",
        "    early_stopping,\n",
        "    lr_scheduler\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KW73KmgOlESY"
      },
      "outputs": [],
      "source": [
        "batch_size = 64\n",
        "epochs = 256\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    x = X_train/255,\n",
        "    y = y_train,\n",
        "    batch_size = batch_size,\n",
        "    epochs = epochs,\n",
        "    validation_data = (X_val/255, y_val),\n",
        "    callbacks = callbacks\n",
        ").history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K3OP5gJjlESZ"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(15,5))\n",
        "plt.plot(history['accuracy'], alpha=.3, color='#ff7f0e', linestyle='--')\n",
        "plt.plot(history['val_accuracy'], alpha=.8, color='#ff7f0e')\n",
        "plt.legend(loc='upper left')\n",
        "plt.title('Accuracy')\n",
        "plt.grid(alpha=.3)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8gcWAEyKlESZ"
      },
      "outputs": [],
      "source": [
        "model.save('SubmissionModelNoMaxPool')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2oN9l7ZAlESZ"
      },
      "outputs": [],
      "source": [
        "# model = tfk.models.load_model('SubmissionModel')\n",
        "\n",
        "predicted_test = np.argmax(model.predict(X_test/255, verbose=\"silent\"), axis=-1)\n",
        "ground_truth_test = np.argmax(y_test, axis=-1)\n",
        "# Accuracy on test set.\n",
        "accuracy_test = sklm.accuracy_score(ground_truth_test, predicted_test)\n",
        "print(f\"Test set accuracy: {accuracy_test:.2%}\")\n",
        "# Precision, recall, and F-score on test set.\n",
        "precision_test = sklm.precision_score(ground_truth_test, predicted_test, average=\"weighted\")\n",
        "recall_test = sklm.recall_score(ground_truth_test, predicted_test, average=\"weighted\")\n",
        "f_measure_test = sklm.f1_score(ground_truth_test, predicted_test, average=\"weighted\")\n",
        "print(f\"Test set precision: {precision_test:.2%}\")\n",
        "print(f\"Test set recall: {recall_test:.2%}\")\n",
        "print(f\"Test set F1: {f_measure_test:.2%}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transfer Learning & Fine Tuning"
      ],
      "metadata": {
        "id": "kOEuagUYikPu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EfficientNet"
      ],
      "metadata": {
        "id": "1k-GCFoSion-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transfer Learning"
      ],
      "metadata": {
        "id": "yhBsg_6qtCW6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr_patience = 7\n",
        "lr_scheduler = tfk.callbacks.ReduceLROnPlateau(\n",
        "    monitor='val_accuracy',\n",
        "    patience=lr_patience,\n",
        "    factor=0.9,\n",
        "    mode='auto',\n",
        "    min_lr=1e-5\n",
        ")\n",
        "\n",
        "early_stopping = tfk.callbacks.EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True, mode='auto')\n",
        "\n",
        "callbacks = [\n",
        "    early_stopping,\n",
        "    lr_scheduler\n",
        "]"
      ],
      "metadata": {
        "id": "p3cr9IartEUL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "enet_model = tf.keras.applications.EfficientNetV2L(\n",
        "    include_top=True,\n",
        "    weights=\"imagenet\",\n",
        "    input_tensor=None,\n",
        "    input_shape=(96,96,3),\n",
        "    pooling=\"avg\",\n",
        "    classes=1000,\n",
        "    classifier_activation=\"softmax\",\n",
        "    include_preprocessing=True,\n",
        ")\n",
        "\n",
        "tfk.utils.plot_model(convnet, show_shapes=True)\n",
        "\n",
        "preprocessing = tf.keras.Sequential([\n",
        "        tfkl.RandomTranslation(0.15,0.15, fill_mode=\"reflect\", interpolation='bilinear'),\n",
        "        tfkl.RandomFlip(\"horizontal_and_vertical\"),\n",
        "        tfkl.RandomRotation(0.15, interpolation='bilinear'),\n",
        "        tfkl.RandomZoom(-0.2, 0.1, interpolation='bilinear')\n",
        "], name='preprocessing')\n",
        "\n",
        "enet_model.trainable = False\n",
        "\n",
        "inputs = tfk.Input(shape=(96, 96, 3))\n",
        "\n",
        "inputs = preprocessing(inputs)\n",
        "\n",
        "x = enet_model(inputs)\n",
        "\n",
        "outputs = tfkl.Dense(2, activation='softmax')(x)\n",
        "\n",
        "enet_model = tfk.Model(inputs=inputs, outputs=outputs, name='model')\n",
        "\n",
        "enet_model.compile(loss=tfk.losses.BinaryCrossentropy(), optimizer=tfk.optimizers.Adam(learning_rate=1e-4), metrics=['accuracy'])\n",
        "\n",
        "enet_model.summary()"
      ],
      "metadata": {
        "id": "q1eNm2svtJoA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tl_history = enet_model.fit(\n",
        "    train_ds_mu,\n",
        "    batch_size = 32,\n",
        "    epochs = 512,\n",
        "    validation_data = ((X_val), y_val),\n",
        "    callbacks = callbacks,\n",
        ").history"
      ],
      "metadata": {
        "id": "UP9_pwn01mcH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "enet_model.save('ENET')\n",
        "\n",
        "predicted_test = np.argmax(enet_model.predict(X_test, verbose=\"silent\"), axis=-1)\n",
        "ground_truth_test = np.argmax(y_test, axis=-1)\n",
        "# Accuracy on test set.\n",
        "accuracy_test = sklm.accuracy_score(ground_truth_test, predicted_test)\n",
        "print(f\"Test set accuracy: {accuracy_test:.2%}\")\n",
        " #Precision, recall, and F-score on test set.\n",
        "precision_test = sklm.precision_score(ground_truth_test, predicted_test, average=\"weighted\")\n",
        "recall_test = sklm.recall_score(ground_truth_test, predicted_test, average=\"weighted\")\n",
        "f_measure_test = sklm.f1_score(ground_truth_test, predicted_test, average=\"weighted\")\n",
        "print(f\"Test set precision: {precision_test:.2%}\")\n",
        "print(f\"Test set recall: {recall_test:.2%}\")\n",
        "print(f\"Test set F1: {f_measure_test:.2%}\")"
      ],
      "metadata": {
        "id": "uV5_ZzmOU0-n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fine Tuning"
      ],
      "metadata": {
        "id": "psJRxgpUSYys"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "enet_model.get_layer('efficientnetv2-l').trainable = True\n",
        "\n",
        "N = 500\n",
        "for i, layer in enumerate(enet_model.get_layer('efficientnetv2-l').layers[:N]):\n",
        "  layer.trainable=False\n",
        "for i, layer in enumerate(enet_model.get_layer('efficientnetv2-l').layers):\n",
        "   print(i, layer.name, layer.trainable)\n",
        "enet_model.summary()"
      ],
      "metadata": {
        "id": "1omas1e9SmQI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr_patience = 10\n",
        "l2_lambda = 5e-5\n",
        "lr_scheduler = tfk.callbacks.ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    patience=lr_patience,\n",
        "    factor=0.9,\n",
        "    mode='min',\n",
        "    min_lr=1e-5\n",
        ")\n",
        "\n",
        "early_stopping = tfk.callbacks.EarlyStopping(monitor='val_accuracy', patience=40, restore_best_weights=True, mode='auto')\n",
        "\n",
        "callbacks2 = [\n",
        "    early_stopping,\n",
        "    lr_scheduler\n",
        "]"
      ],
      "metadata": {
        "id": "dFGVM5EDUNeh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "enet_model.compile(loss=tfk.losses.BinaryCrossentropy(), optimizer=tfk.optimizers.Adam(1e-5), metrics='accuracy')\n",
        "\n",
        "# Fine-tune the model\n",
        "ft_history = enet_model.fit(\n",
        "    x = tf.keras.applications.efficientnet_v2.preprocess_input(X_train),\n",
        "    y = y_train,\n",
        "    batch_size = 128,\n",
        "    epochs = 512,\n",
        "    validation_data = (tf.keras.applications.efficientnet_v2.preprocess_input(X_val), y_val),\n",
        "    callbacks = callbacks2\n",
        ").history"
      ],
      "metadata": {
        "id": "CswPMYO0UPDk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qlP4uB4V8w8Q"
      },
      "source": [
        "## ConvNeXt Base (Final Model)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-QGY8qJh8w8a"
      },
      "source": [
        "### Transfer Learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WO63B2Aj8w8b"
      },
      "outputs": [],
      "source": [
        "# Declare callbacks\n",
        "lr_patience = 7\n",
        "lr_scheduler = tfk.callbacks.ReduceLROnPlateau(\n",
        "    monitor='val_accuracy',\n",
        "    patience=lr_patience,\n",
        "    factor=0.9,\n",
        "    mode='auto',\n",
        "    min_lr=1e-5\n",
        ")\n",
        "\n",
        "early_stopping = tfk.callbacks.EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True, mode='auto', start_from_epoch=20)\n",
        "\n",
        "callbacks = [\n",
        "    early_stopping,\n",
        "    lr_scheduler\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VBv-Jzu88w8b",
        "outputId": "64cd847f-eaf0-41dc-dea8-6c3088d3e434"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/convnext/convnext_base_notop.h5\n",
            "350926856/350926856 [==============================] - 17s 0us/step\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 96, 96, 3)]       0         \n",
            "                                                                 \n",
            " convnext_base (Functional)  (None, 1024)              87566464  \n",
            "                                                                 \n",
            " classification2 (Dense)     (None, 64)                65600     \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 64)                0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2)                 130       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 87632194 (334.29 MB)\n",
            "Trainable params: 65730 (256.76 KB)\n",
            "Non-trainable params: 87566464 (334.04 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "convnet = tf.keras.applications.ConvNeXtBase(\n",
        "    model_name=\"convnext_base\",\n",
        "    include_top=False,\n",
        "    include_preprocessing=True,\n",
        "    weights=\"imagenet\",\n",
        "    input_tensor=None,\n",
        "    input_shape=(96,96,3),\n",
        "    pooling=\"avg\",\n",
        "    classes=2,\n",
        "    classifier_activation=\"softmax\",\n",
        ")\n",
        "tfk.utils.plot_model(convnet, show_shapes=True)\n",
        "\n",
        "# Preprocessing applied only during training\n",
        "preprocessing = tf.keras.Sequential([\n",
        "        tfkl.RandomTranslation(0.15,0.15, fill_mode=\"reflect\", interpolation='bilinear'),\n",
        "        tfkl.RandomFlip(\"horizontal_and_vertical\"),\n",
        "        tfkl.RandomRotation(0.15, interpolation='bilinear'),\n",
        "        tfkl.RandomZoom(-0.2, 0.1, interpolation='bilinear')\n",
        "], name='preprocessing')\n",
        "\n",
        "# Freeze all layers\n",
        "convnet.trainable = False\n",
        "\n",
        "inputs = tfk.Input(shape=(96, 96, 3))\n",
        "\n",
        "inputs = preprocessing(inputs)\n",
        "\n",
        "x = convnet(inputs)\n",
        "\n",
        "# Add just one dense layer\n",
        "x = tfkl.Dense(units=64, activation='relu',\n",
        "               kernel_initializer=tfk.initializers.HeUniform(seed=seed),\n",
        "               name='classification2')(x)\n",
        "# Add dropout to reduce overfitting\n",
        "x = tfkl.Dropout(0.7, seed=seed)(x)\n",
        "\n",
        "# Use softmax as output function\n",
        "outputs = tfkl.Dense(2, activation='softmax')(x)\n",
        "\n",
        "convnet = tfk.Model(inputs=inputs, outputs=outputs, name='model')\n",
        "\n",
        "# Compile model using binary crossentropy because we have two classes\n",
        "convnet.compile(loss=tfk.losses.BinaryCrossentropy(), optimizer=tfk.optimizers.Adam(learning_rate=1e-4), metrics=['accuracy'])\n",
        "\n",
        "convnet.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_-2Y9_d8w8b",
        "outputId": "a0b57a5c-4dbb-4332-e6c2-20d769f9dee7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/512\n",
            "74/74 [==============================] - 67s 483ms/step - loss: 0.8062 - accuracy: 0.5360 - val_loss: 0.6562 - val_accuracy: 0.6817 - lr: 1.0000e-04\n",
            "Epoch 2/512\n",
            "74/74 [==============================] - 21s 279ms/step - loss: 0.6885 - accuracy: 0.5831 - val_loss: 0.6268 - val_accuracy: 0.7441 - lr: 1.0000e-04\n",
            "Epoch 3/512\n",
            "74/74 [==============================] - 21s 284ms/step - loss: 0.6634 - accuracy: 0.6251 - val_loss: 0.6161 - val_accuracy: 0.7495 - lr: 1.0000e-04\n",
            "Epoch 4/512\n",
            "74/74 [==============================] - 22s 302ms/step - loss: 0.6454 - accuracy: 0.6491 - val_loss: 0.5850 - val_accuracy: 0.7656 - lr: 1.0000e-04\n",
            "Epoch 5/512\n",
            "74/74 [==============================] - 23s 305ms/step - loss: 0.6256 - accuracy: 0.6753 - val_loss: 0.5550 - val_accuracy: 0.7946 - lr: 1.0000e-04\n",
            "Epoch 6/512\n",
            "74/74 [==============================] - 23s 304ms/step - loss: 0.6180 - accuracy: 0.6824 - val_loss: 0.5239 - val_accuracy: 0.8237 - lr: 1.0000e-04\n",
            "Epoch 7/512\n",
            "74/74 [==============================] - 21s 284ms/step - loss: 0.5971 - accuracy: 0.7043 - val_loss: 0.5004 - val_accuracy: 0.8247 - lr: 1.0000e-04\n",
            "Epoch 8/512\n",
            "74/74 [==============================] - 21s 285ms/step - loss: 0.5880 - accuracy: 0.7120 - val_loss: 0.4825 - val_accuracy: 0.8312 - lr: 1.0000e-04\n"
          ]
        }
      ],
      "source": [
        "# Train with mixup data\n",
        "tl_history = convnet.fit(\n",
        "    train_ds_mu,\n",
        "    batch_size = 32,\n",
        "    epochs = 512,\n",
        "    validation_data = ((X_val), y_val),\n",
        "    callbacks = callbacks,\n",
        ").history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7VSGEUzx8w8c"
      },
      "outputs": [],
      "source": [
        "convnet.save('SubmissionModel_ConvB_Final3_onlyTL-2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "obVpZaMh8w8c"
      },
      "outputs": [],
      "source": [
        "predicted_test = np.argmax(convnet.predict(X_test, verbose=\"silent\"), axis=-1)\n",
        "ground_truth_test = np.argmax(y_test, axis=-1)\n",
        "# Accuracy on test set\n",
        "accuracy_test = sklm.accuracy_score(ground_truth_test, predicted_test)\n",
        "print(f\"Test set accuracy: {accuracy_test:.2%}\")\n",
        "# Precision, recall, and F-score on test set.\n",
        "precision_test = sklm.precision_score(ground_truth_test, predicted_test, average=\"weighted\")\n",
        "recall_test = sklm.recall_score(ground_truth_test, predicted_test, average=\"weighted\")\n",
        "f_measure_test = sklm.f1_score(ground_truth_test, predicted_test, average=\"weighted\")\n",
        "print(f\"Test set precision: {precision_test:.2%}\")\n",
        "print(f\"Test set recall: {recall_test:.2%}\")\n",
        "print(f\"Test set F1: {f_measure_test:.2%}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fine Tuning"
      ],
      "metadata": {
        "id": "ftNEBlZVHSTm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "convnet = tfk.models.load_model('SubmissionModel_ConvB_Final3_onlyTL-2')"
      ],
      "metadata": {
        "id": "vAftbT-4ca3s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "si88quGo8w8c"
      },
      "outputs": [],
      "source": [
        "# Set all layers as trainable\n",
        "convnet.get_layer('convnext_base').trainable = True\n",
        "\n",
        "N = 200\n",
        "# Freeze first 200 layers\n",
        "for i, layer in enumerate(convnet.get_layer('convnext_base').layers[:N]):\n",
        "  layer.trainable=False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GT8ELMOB8w8c"
      },
      "outputs": [],
      "source": [
        "# Declare callbacks\n",
        "lr_patience = 5\n",
        "l2_lambda = 1e-4\n",
        "lr_scheduler = tfk.callbacks.ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    patience=lr_patience,\n",
        "    factor=0.9,\n",
        "    mode='min',\n",
        "    min_lr=1e-6\n",
        ")\n",
        "\n",
        "early_stopping = tfk.callbacks.EarlyStopping(monitor='val_loss', patience=7, restore_best_weights=True, mode='auto', start_from_epoch=1)\n",
        "\n",
        "callbacks2 = [\n",
        "    early_stopping,\n",
        "    lr_scheduler\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q0BdHlO_8w8d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bd9c59d-f5b9-4a91-e521-9bd91f88375c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/256\n",
            "59/59 [==============================] - 84s 763ms/step - loss: 0.4461 - accuracy: 0.8185 - val_loss: 0.3286 - val_accuracy: 0.8710 - lr: 1.0000e-06\n",
            "Epoch 2/256\n",
            "59/59 [==============================] - 27s 465ms/step - loss: 0.4429 - accuracy: 0.8226 - val_loss: 0.3257 - val_accuracy: 0.8710 - lr: 1.0000e-06\n",
            "Epoch 3/256\n",
            "59/59 [==============================] - 26s 443ms/step - loss: 0.4575 - accuracy: 0.8258 - val_loss: 0.3236 - val_accuracy: 0.8667 - lr: 1.0000e-06\n",
            "Epoch 4/256\n",
            "59/59 [==============================] - 26s 446ms/step - loss: 0.4476 - accuracy: 0.8185 - val_loss: 0.3214 - val_accuracy: 0.8645 - lr: 1.0000e-06\n",
            "Epoch 5/256\n",
            "59/59 [==============================] - 26s 441ms/step - loss: 0.4429 - accuracy: 0.8226 - val_loss: 0.3200 - val_accuracy: 0.8656 - lr: 1.0000e-06\n",
            "Epoch 6/256\n",
            "59/59 [==============================] - 26s 448ms/step - loss: 0.4441 - accuracy: 0.8261 - val_loss: 0.3191 - val_accuracy: 0.8656 - lr: 1.0000e-06\n",
            "Epoch 7/256\n",
            "59/59 [==============================] - 26s 433ms/step - loss: 0.4405 - accuracy: 0.8250 - val_loss: 0.3207 - val_accuracy: 0.8667 - lr: 1.0000e-06\n",
            "Epoch 8/256\n",
            "59/59 [==============================] - 26s 438ms/step - loss: 0.4398 - accuracy: 0.8177 - val_loss: 0.3190 - val_accuracy: 0.8656 - lr: 1.0000e-06\n",
            "Epoch 9/256\n",
            "59/59 [==============================] - 26s 441ms/step - loss: 0.4343 - accuracy: 0.8298 - val_loss: 0.3161 - val_accuracy: 0.8667 - lr: 1.0000e-06\n",
            "Epoch 10/256\n",
            "59/59 [==============================] - 27s 456ms/step - loss: 0.4324 - accuracy: 0.8339 - val_loss: 0.3142 - val_accuracy: 0.8677 - lr: 1.0000e-06\n",
            "Epoch 11/256\n",
            "59/59 [==============================] - 26s 442ms/step - loss: 0.4248 - accuracy: 0.8368 - val_loss: 0.3126 - val_accuracy: 0.8677 - lr: 1.0000e-06\n",
            "Epoch 12/256\n",
            "59/59 [==============================] - 26s 437ms/step - loss: 0.4366 - accuracy: 0.8263 - val_loss: 0.3116 - val_accuracy: 0.8677 - lr: 1.0000e-06\n",
            "Epoch 13/256\n",
            "59/59 [==============================] - 25s 431ms/step - loss: 0.4393 - accuracy: 0.8272 - val_loss: 0.3110 - val_accuracy: 0.8699 - lr: 1.0000e-06\n",
            "Epoch 14/256\n",
            "59/59 [==============================] - 26s 436ms/step - loss: 0.4336 - accuracy: 0.8301 - val_loss: 0.3097 - val_accuracy: 0.8699 - lr: 1.0000e-06\n",
            "Epoch 15/256\n",
            "59/59 [==============================] - 31s 530ms/step - loss: 0.4308 - accuracy: 0.8333 - val_loss: 0.3079 - val_accuracy: 0.8699 - lr: 1.0000e-06\n",
            "Epoch 16/256\n",
            "59/59 [==============================] - 26s 443ms/step - loss: 0.4213 - accuracy: 0.8390 - val_loss: 0.3061 - val_accuracy: 0.8699 - lr: 1.0000e-06\n",
            "Epoch 17/256\n",
            "59/59 [==============================] - 26s 444ms/step - loss: 0.4215 - accuracy: 0.8325 - val_loss: 0.3050 - val_accuracy: 0.8720 - lr: 1.0000e-06\n",
            "Epoch 18/256\n",
            "59/59 [==============================] - 26s 436ms/step - loss: 0.4199 - accuracy: 0.8366 - val_loss: 0.3031 - val_accuracy: 0.8731 - lr: 1.0000e-06\n",
            "Epoch 19/256\n",
            "59/59 [==============================] - 26s 438ms/step - loss: 0.4252 - accuracy: 0.8333 - val_loss: 0.3033 - val_accuracy: 0.8720 - lr: 1.0000e-06\n",
            "Epoch 20/256\n",
            "59/59 [==============================] - 26s 442ms/step - loss: 0.4177 - accuracy: 0.8406 - val_loss: 0.3022 - val_accuracy: 0.8720 - lr: 1.0000e-06\n",
            "Epoch 21/256\n",
            "59/59 [==============================] - 26s 438ms/step - loss: 0.4160 - accuracy: 0.8446 - val_loss: 0.3003 - val_accuracy: 0.8742 - lr: 1.0000e-06\n",
            "Epoch 22/256\n",
            "59/59 [==============================] - 31s 535ms/step - loss: 0.4199 - accuracy: 0.8398 - val_loss: 0.2986 - val_accuracy: 0.8796 - lr: 1.0000e-06\n",
            "Epoch 23/256\n",
            "59/59 [==============================] - 25s 427ms/step - loss: 0.4110 - accuracy: 0.8374 - val_loss: 0.2972 - val_accuracy: 0.8806 - lr: 1.0000e-06\n",
            "Epoch 24/256\n",
            "59/59 [==============================] - 26s 446ms/step - loss: 0.4124 - accuracy: 0.8368 - val_loss: 0.2963 - val_accuracy: 0.8785 - lr: 1.0000e-06\n",
            "Epoch 25/256\n",
            "59/59 [==============================] - 26s 441ms/step - loss: 0.4218 - accuracy: 0.8344 - val_loss: 0.2959 - val_accuracy: 0.8785 - lr: 1.0000e-06\n",
            "Epoch 26/256\n",
            "59/59 [==============================] - 25s 428ms/step - loss: 0.4198 - accuracy: 0.8336 - val_loss: 0.2940 - val_accuracy: 0.8817 - lr: 1.0000e-06\n",
            "Epoch 27/256\n",
            "59/59 [==============================] - 25s 427ms/step - loss: 0.4075 - accuracy: 0.8473 - val_loss: 0.2938 - val_accuracy: 0.8785 - lr: 1.0000e-06\n",
            "Epoch 28/256\n",
            "59/59 [==============================] - 26s 448ms/step - loss: 0.4157 - accuracy: 0.8457 - val_loss: 0.2926 - val_accuracy: 0.8806 - lr: 1.0000e-06\n",
            "Epoch 29/256\n",
            "59/59 [==============================] - 26s 441ms/step - loss: 0.4099 - accuracy: 0.8392 - val_loss: 0.2914 - val_accuracy: 0.8806 - lr: 1.0000e-06\n",
            "Epoch 30/256\n",
            "59/59 [==============================] - 25s 428ms/step - loss: 0.4040 - accuracy: 0.8425 - val_loss: 0.2912 - val_accuracy: 0.8785 - lr: 1.0000e-06\n",
            "Epoch 31/256\n",
            "59/59 [==============================] - 25s 428ms/step - loss: 0.4052 - accuracy: 0.8425 - val_loss: 0.2891 - val_accuracy: 0.8839 - lr: 1.0000e-06\n",
            "Epoch 32/256\n",
            "59/59 [==============================] - 26s 436ms/step - loss: 0.4091 - accuracy: 0.8401 - val_loss: 0.2878 - val_accuracy: 0.8828 - lr: 1.0000e-06\n",
            "Epoch 33/256\n",
            "59/59 [==============================] - 26s 440ms/step - loss: 0.4064 - accuracy: 0.8484 - val_loss: 0.2870 - val_accuracy: 0.8806 - lr: 1.0000e-06\n",
            "Epoch 34/256\n",
            "59/59 [==============================] - 25s 426ms/step - loss: 0.4087 - accuracy: 0.8449 - val_loss: 0.2870 - val_accuracy: 0.8828 - lr: 1.0000e-06\n",
            "Epoch 35/256\n",
            "59/59 [==============================] - 26s 435ms/step - loss: 0.3960 - accuracy: 0.8575 - val_loss: 0.2852 - val_accuracy: 0.8817 - lr: 1.0000e-06\n",
            "Epoch 36/256\n",
            "59/59 [==============================] - 26s 443ms/step - loss: 0.4044 - accuracy: 0.8535 - val_loss: 0.2835 - val_accuracy: 0.8817 - lr: 1.0000e-06\n",
            "Epoch 37/256\n",
            "59/59 [==============================] - 25s 429ms/step - loss: 0.4037 - accuracy: 0.8417 - val_loss: 0.2829 - val_accuracy: 0.8817 - lr: 1.0000e-06\n",
            "Epoch 38/256\n",
            "59/59 [==============================] - 26s 442ms/step - loss: 0.3964 - accuracy: 0.8540 - val_loss: 0.2820 - val_accuracy: 0.8817 - lr: 1.0000e-06\n",
            "Epoch 39/256\n",
            "59/59 [==============================] - 26s 435ms/step - loss: 0.4110 - accuracy: 0.8476 - val_loss: 0.2820 - val_accuracy: 0.8817 - lr: 1.0000e-06\n",
            "Epoch 40/256\n",
            "59/59 [==============================] - 31s 530ms/step - loss: 0.4037 - accuracy: 0.8516 - val_loss: 0.2809 - val_accuracy: 0.8817 - lr: 1.0000e-06\n",
            "Epoch 41/256\n",
            "59/59 [==============================] - 25s 426ms/step - loss: 0.3989 - accuracy: 0.8457 - val_loss: 0.2804 - val_accuracy: 0.8806 - lr: 1.0000e-06\n",
            "Epoch 42/256\n",
            "59/59 [==============================] - 25s 428ms/step - loss: 0.3956 - accuracy: 0.8516 - val_loss: 0.2798 - val_accuracy: 0.8785 - lr: 1.0000e-06\n",
            "Epoch 43/256\n",
            "59/59 [==============================] - 26s 443ms/step - loss: 0.3898 - accuracy: 0.8608 - val_loss: 0.2785 - val_accuracy: 0.8817 - lr: 1.0000e-06\n",
            "Epoch 44/256\n",
            "59/59 [==============================] - 26s 432ms/step - loss: 0.3957 - accuracy: 0.8470 - val_loss: 0.2774 - val_accuracy: 0.8806 - lr: 1.0000e-06\n",
            "Epoch 45/256\n",
            "59/59 [==============================] - 25s 423ms/step - loss: 0.4045 - accuracy: 0.8567 - val_loss: 0.2783 - val_accuracy: 0.8839 - lr: 1.0000e-06\n",
            "Epoch 46/256\n",
            "59/59 [==============================] - 26s 443ms/step - loss: 0.3938 - accuracy: 0.8554 - val_loss: 0.2762 - val_accuracy: 0.8839 - lr: 1.0000e-06\n",
            "Epoch 47/256\n",
            "59/59 [==============================] - 26s 439ms/step - loss: 0.3906 - accuracy: 0.8530 - val_loss: 0.2760 - val_accuracy: 0.8828 - lr: 1.0000e-06\n",
            "Epoch 48/256\n",
            "59/59 [==============================] - 25s 432ms/step - loss: 0.3957 - accuracy: 0.8508 - val_loss: 0.2743 - val_accuracy: 0.8849 - lr: 1.0000e-06\n",
            "Epoch 49/256\n",
            "59/59 [==============================] - 26s 439ms/step - loss: 0.3834 - accuracy: 0.8556 - val_loss: 0.2736 - val_accuracy: 0.8860 - lr: 1.0000e-06\n",
            "Epoch 50/256\n",
            "59/59 [==============================] - 26s 434ms/step - loss: 0.3838 - accuracy: 0.8567 - val_loss: 0.2727 - val_accuracy: 0.8849 - lr: 1.0000e-06\n",
            "Epoch 51/256\n",
            "59/59 [==============================] - 26s 441ms/step - loss: 0.3914 - accuracy: 0.8519 - val_loss: 0.2712 - val_accuracy: 0.8871 - lr: 1.0000e-06\n",
            "Epoch 52/256\n",
            "59/59 [==============================] - 26s 435ms/step - loss: 0.3877 - accuracy: 0.8573 - val_loss: 0.2702 - val_accuracy: 0.8882 - lr: 1.0000e-06\n",
            "Epoch 53/256\n",
            "59/59 [==============================] - 26s 442ms/step - loss: 0.3781 - accuracy: 0.8645 - val_loss: 0.2686 - val_accuracy: 0.8892 - lr: 1.0000e-06\n",
            "Epoch 54/256\n",
            "59/59 [==============================] - 26s 440ms/step - loss: 0.3846 - accuracy: 0.8634 - val_loss: 0.2680 - val_accuracy: 0.8860 - lr: 1.0000e-06\n",
            "Epoch 55/256\n",
            "59/59 [==============================] - 25s 431ms/step - loss: 0.3741 - accuracy: 0.8669 - val_loss: 0.2672 - val_accuracy: 0.8871 - lr: 1.0000e-06\n",
            "Epoch 56/256\n",
            "59/59 [==============================] - 26s 437ms/step - loss: 0.3879 - accuracy: 0.8556 - val_loss: 0.2676 - val_accuracy: 0.8860 - lr: 1.0000e-06\n",
            "Epoch 57/256\n",
            "59/59 [==============================] - 26s 448ms/step - loss: 0.3947 - accuracy: 0.8597 - val_loss: 0.2669 - val_accuracy: 0.8892 - lr: 1.0000e-06\n",
            "Epoch 58/256\n",
            "59/59 [==============================] - 25s 431ms/step - loss: 0.3868 - accuracy: 0.8637 - val_loss: 0.2672 - val_accuracy: 0.8892 - lr: 1.0000e-06\n",
            "Epoch 59/256\n",
            "59/59 [==============================] - 26s 445ms/step - loss: 0.3882 - accuracy: 0.8621 - val_loss: 0.2661 - val_accuracy: 0.8871 - lr: 1.0000e-06\n",
            "Epoch 60/256\n",
            "59/59 [==============================] - 25s 423ms/step - loss: 0.3750 - accuracy: 0.8694 - val_loss: 0.2673 - val_accuracy: 0.8860 - lr: 1.0000e-06\n",
            "Epoch 61/256\n",
            "59/59 [==============================] - 26s 440ms/step - loss: 0.3824 - accuracy: 0.8715 - val_loss: 0.2654 - val_accuracy: 0.8882 - lr: 1.0000e-06\n",
            "Epoch 62/256\n",
            "59/59 [==============================] - 26s 435ms/step - loss: 0.3747 - accuracy: 0.8583 - val_loss: 0.2636 - val_accuracy: 0.8935 - lr: 1.0000e-06\n",
            "Epoch 63/256\n",
            "59/59 [==============================] - 26s 444ms/step - loss: 0.3749 - accuracy: 0.8718 - val_loss: 0.2635 - val_accuracy: 0.8892 - lr: 1.0000e-06\n",
            "Epoch 64/256\n",
            "59/59 [==============================] - 26s 433ms/step - loss: 0.3791 - accuracy: 0.8586 - val_loss: 0.2621 - val_accuracy: 0.8935 - lr: 1.0000e-06\n",
            "Epoch 65/256\n",
            "59/59 [==============================] - 26s 443ms/step - loss: 0.3706 - accuracy: 0.8728 - val_loss: 0.2624 - val_accuracy: 0.8914 - lr: 1.0000e-06\n",
            "Epoch 66/256\n",
            "59/59 [==============================] - 26s 434ms/step - loss: 0.3739 - accuracy: 0.8659 - val_loss: 0.2613 - val_accuracy: 0.8914 - lr: 1.0000e-06\n",
            "Epoch 67/256\n",
            "59/59 [==============================] - 26s 443ms/step - loss: 0.3632 - accuracy: 0.8718 - val_loss: 0.2604 - val_accuracy: 0.8903 - lr: 1.0000e-06\n",
            "Epoch 68/256\n",
            "59/59 [==============================] - 26s 437ms/step - loss: 0.3661 - accuracy: 0.8747 - val_loss: 0.2600 - val_accuracy: 0.8903 - lr: 1.0000e-06\n",
            "Epoch 69/256\n",
            "59/59 [==============================] - 26s 435ms/step - loss: 0.3701 - accuracy: 0.8589 - val_loss: 0.2584 - val_accuracy: 0.8935 - lr: 1.0000e-06\n",
            "Epoch 70/256\n",
            "59/59 [==============================] - 25s 424ms/step - loss: 0.3709 - accuracy: 0.8704 - val_loss: 0.2585 - val_accuracy: 0.8935 - lr: 1.0000e-06\n",
            "Epoch 71/256\n",
            "59/59 [==============================] - 25s 432ms/step - loss: 0.3676 - accuracy: 0.8742 - val_loss: 0.2582 - val_accuracy: 0.8925 - lr: 1.0000e-06\n",
            "Epoch 72/256\n",
            "59/59 [==============================] - 26s 444ms/step - loss: 0.3690 - accuracy: 0.8688 - val_loss: 0.2570 - val_accuracy: 0.8989 - lr: 1.0000e-06\n",
            "Epoch 73/256\n",
            "59/59 [==============================] - 26s 441ms/step - loss: 0.3689 - accuracy: 0.8685 - val_loss: 0.2562 - val_accuracy: 0.9000 - lr: 1.0000e-06\n",
            "Epoch 74/256\n",
            "59/59 [==============================] - 26s 446ms/step - loss: 0.3737 - accuracy: 0.8707 - val_loss: 0.2560 - val_accuracy: 0.8989 - lr: 1.0000e-06\n",
            "Epoch 75/256\n",
            "59/59 [==============================] - 26s 441ms/step - loss: 0.3645 - accuracy: 0.8702 - val_loss: 0.2551 - val_accuracy: 0.8968 - lr: 1.0000e-06\n",
            "Epoch 76/256\n",
            "59/59 [==============================] - 26s 440ms/step - loss: 0.3630 - accuracy: 0.8742 - val_loss: 0.2551 - val_accuracy: 0.8935 - lr: 1.0000e-06\n",
            "Epoch 77/256\n",
            "59/59 [==============================] - 26s 433ms/step - loss: 0.3738 - accuracy: 0.8747 - val_loss: 0.2538 - val_accuracy: 0.8968 - lr: 1.0000e-06\n",
            "Epoch 78/256\n",
            "59/59 [==============================] - 26s 437ms/step - loss: 0.3642 - accuracy: 0.8720 - val_loss: 0.2538 - val_accuracy: 0.8989 - lr: 1.0000e-06\n",
            "Epoch 79/256\n",
            "59/59 [==============================] - 26s 448ms/step - loss: 0.3622 - accuracy: 0.8728 - val_loss: 0.2525 - val_accuracy: 0.9000 - lr: 1.0000e-06\n",
            "Epoch 80/256\n",
            "59/59 [==============================] - 25s 426ms/step - loss: 0.3663 - accuracy: 0.8742 - val_loss: 0.2516 - val_accuracy: 0.9000 - lr: 1.0000e-06\n",
            "Epoch 81/256\n",
            "59/59 [==============================] - 26s 449ms/step - loss: 0.3606 - accuracy: 0.8758 - val_loss: 0.2509 - val_accuracy: 0.9000 - lr: 1.0000e-06\n",
            "Epoch 82/256\n",
            "59/59 [==============================] - 26s 443ms/step - loss: 0.3555 - accuracy: 0.8742 - val_loss: 0.2496 - val_accuracy: 0.8989 - lr: 1.0000e-06\n",
            "Epoch 83/256\n",
            "59/59 [==============================] - 26s 435ms/step - loss: 0.3519 - accuracy: 0.8825 - val_loss: 0.2513 - val_accuracy: 0.8968 - lr: 1.0000e-06\n",
            "Epoch 84/256\n",
            "59/59 [==============================] - 27s 452ms/step - loss: 0.3640 - accuracy: 0.8782 - val_loss: 0.2488 - val_accuracy: 0.9000 - lr: 1.0000e-06\n",
            "Epoch 85/256\n",
            "59/59 [==============================] - 26s 436ms/step - loss: 0.3539 - accuracy: 0.8769 - val_loss: 0.2490 - val_accuracy: 0.8978 - lr: 1.0000e-06\n",
            "Epoch 86/256\n",
            "59/59 [==============================] - 26s 440ms/step - loss: 0.3540 - accuracy: 0.8831 - val_loss: 0.2493 - val_accuracy: 0.9011 - lr: 1.0000e-06\n",
            "Epoch 87/256\n",
            "59/59 [==============================] - 26s 445ms/step - loss: 0.3595 - accuracy: 0.8723 - val_loss: 0.2485 - val_accuracy: 0.9000 - lr: 1.0000e-06\n",
            "Epoch 88/256\n",
            "59/59 [==============================] - 31s 526ms/step - loss: 0.3607 - accuracy: 0.8766 - val_loss: 0.2486 - val_accuracy: 0.9000 - lr: 1.0000e-06\n",
            "Epoch 89/256\n",
            "59/59 [==============================] - 26s 443ms/step - loss: 0.3517 - accuracy: 0.8847 - val_loss: 0.2482 - val_accuracy: 0.9022 - lr: 1.0000e-06\n",
            "Epoch 90/256\n",
            "59/59 [==============================] - 26s 444ms/step - loss: 0.3514 - accuracy: 0.8737 - val_loss: 0.2477 - val_accuracy: 0.9000 - lr: 1.0000e-06\n",
            "Epoch 91/256\n",
            "59/59 [==============================] - 26s 444ms/step - loss: 0.3526 - accuracy: 0.8844 - val_loss: 0.2462 - val_accuracy: 0.9000 - lr: 1.0000e-06\n",
            "Epoch 92/256\n",
            "59/59 [==============================] - 26s 446ms/step - loss: 0.3581 - accuracy: 0.8702 - val_loss: 0.2461 - val_accuracy: 0.8989 - lr: 1.0000e-06\n",
            "Epoch 93/256\n",
            "59/59 [==============================] - 26s 443ms/step - loss: 0.3607 - accuracy: 0.8796 - val_loss: 0.2452 - val_accuracy: 0.8989 - lr: 1.0000e-06\n",
            "Epoch 94/256\n",
            "59/59 [==============================] - 26s 445ms/step - loss: 0.3652 - accuracy: 0.8750 - val_loss: 0.2452 - val_accuracy: 0.9000 - lr: 1.0000e-06\n",
            "Epoch 95/256\n",
            "59/59 [==============================] - 26s 440ms/step - loss: 0.3474 - accuracy: 0.8815 - val_loss: 0.2442 - val_accuracy: 0.9000 - lr: 1.0000e-06\n",
            "Epoch 96/256\n",
            "59/59 [==============================] - 26s 434ms/step - loss: 0.3501 - accuracy: 0.8815 - val_loss: 0.2437 - val_accuracy: 0.9000 - lr: 1.0000e-06\n",
            "Epoch 97/256\n",
            "59/59 [==============================] - 28s 475ms/step - loss: 0.3463 - accuracy: 0.8841 - val_loss: 0.2432 - val_accuracy: 0.9032 - lr: 1.0000e-06\n",
            "Epoch 98/256\n",
            "59/59 [==============================] - 27s 451ms/step - loss: 0.3417 - accuracy: 0.8817 - val_loss: 0.2425 - val_accuracy: 0.9000 - lr: 1.0000e-06\n",
            "Epoch 99/256\n",
            "59/59 [==============================] - 27s 452ms/step - loss: 0.3504 - accuracy: 0.8820 - val_loss: 0.2418 - val_accuracy: 0.9011 - lr: 1.0000e-06\n",
            "Epoch 100/256\n",
            "59/59 [==============================] - 25s 429ms/step - loss: 0.3480 - accuracy: 0.8841 - val_loss: 0.2410 - val_accuracy: 0.9032 - lr: 1.0000e-06\n",
            "Epoch 101/256\n",
            "59/59 [==============================] - 26s 447ms/step - loss: 0.3512 - accuracy: 0.8793 - val_loss: 0.2404 - val_accuracy: 0.9022 - lr: 1.0000e-06\n",
            "Epoch 102/256\n",
            "59/59 [==============================] - 26s 438ms/step - loss: 0.3454 - accuracy: 0.8763 - val_loss: 0.2405 - val_accuracy: 0.8989 - lr: 1.0000e-06\n",
            "Epoch 103/256\n",
            "59/59 [==============================] - 26s 440ms/step - loss: 0.3381 - accuracy: 0.8868 - val_loss: 0.2409 - val_accuracy: 0.8978 - lr: 1.0000e-06\n",
            "Epoch 104/256\n",
            "59/59 [==============================] - 26s 444ms/step - loss: 0.3458 - accuracy: 0.8858 - val_loss: 0.2396 - val_accuracy: 0.9022 - lr: 1.0000e-06\n",
            "Epoch 105/256\n",
            "59/59 [==============================] - 26s 442ms/step - loss: 0.3468 - accuracy: 0.8849 - val_loss: 0.2406 - val_accuracy: 0.9000 - lr: 1.0000e-06\n",
            "Epoch 106/256\n",
            "59/59 [==============================] - 26s 438ms/step - loss: 0.3460 - accuracy: 0.8927 - val_loss: 0.2396 - val_accuracy: 0.9000 - lr: 1.0000e-06\n",
            "Epoch 107/256\n",
            "59/59 [==============================] - 25s 427ms/step - loss: 0.3434 - accuracy: 0.8960 - val_loss: 0.2382 - val_accuracy: 0.9032 - lr: 1.0000e-06\n",
            "Epoch 108/256\n",
            "59/59 [==============================] - 26s 436ms/step - loss: 0.3369 - accuracy: 0.8941 - val_loss: 0.2385 - val_accuracy: 0.9032 - lr: 1.0000e-06\n",
            "Epoch 109/256\n",
            "59/59 [==============================] - 26s 443ms/step - loss: 0.3406 - accuracy: 0.8876 - val_loss: 0.2380 - val_accuracy: 0.9000 - lr: 1.0000e-06\n",
            "Epoch 110/256\n",
            "59/59 [==============================] - 26s 445ms/step - loss: 0.3451 - accuracy: 0.8898 - val_loss: 0.2371 - val_accuracy: 0.9011 - lr: 1.0000e-06\n",
            "Epoch 111/256\n",
            "59/59 [==============================] - 31s 534ms/step - loss: 0.3332 - accuracy: 0.8914 - val_loss: 0.2378 - val_accuracy: 0.9022 - lr: 1.0000e-06\n",
            "Epoch 112/256\n",
            "59/59 [==============================] - 26s 437ms/step - loss: 0.3261 - accuracy: 0.8981 - val_loss: 0.2378 - val_accuracy: 0.9011 - lr: 1.0000e-06\n",
            "Epoch 113/256\n",
            "59/59 [==============================] - 27s 457ms/step - loss: 0.3321 - accuracy: 0.8882 - val_loss: 0.2368 - val_accuracy: 0.9032 - lr: 1.0000e-06\n",
            "Epoch 114/256\n",
            "59/59 [==============================] - 25s 431ms/step - loss: 0.3317 - accuracy: 0.8938 - val_loss: 0.2354 - val_accuracy: 0.9032 - lr: 1.0000e-06\n",
            "Epoch 115/256\n",
            "59/59 [==============================] - 26s 434ms/step - loss: 0.3375 - accuracy: 0.8898 - val_loss: 0.2350 - val_accuracy: 0.9032 - lr: 1.0000e-06\n",
            "Epoch 116/256\n",
            "59/59 [==============================] - 26s 447ms/step - loss: 0.3295 - accuracy: 0.8954 - val_loss: 0.2341 - val_accuracy: 0.9043 - lr: 1.0000e-06\n",
            "Epoch 117/256\n",
            "59/59 [==============================] - 25s 422ms/step - loss: 0.3323 - accuracy: 0.8898 - val_loss: 0.2342 - val_accuracy: 0.9043 - lr: 1.0000e-06\n",
            "Epoch 118/256\n",
            "59/59 [==============================] - 26s 439ms/step - loss: 0.3245 - accuracy: 0.8968 - val_loss: 0.2343 - val_accuracy: 0.9032 - lr: 1.0000e-06\n",
            "Epoch 119/256\n",
            "59/59 [==============================] - 26s 434ms/step - loss: 0.3372 - accuracy: 0.8927 - val_loss: 0.2341 - val_accuracy: 0.9022 - lr: 1.0000e-06\n",
            "Epoch 120/256\n",
            "59/59 [==============================] - 26s 439ms/step - loss: 0.3288 - accuracy: 0.8879 - val_loss: 0.2330 - val_accuracy: 0.9043 - lr: 1.0000e-06\n",
            "Epoch 121/256\n",
            "59/59 [==============================] - 26s 441ms/step - loss: 0.3452 - accuracy: 0.8863 - val_loss: 0.2324 - val_accuracy: 0.9054 - lr: 1.0000e-06\n",
            "Epoch 122/256\n",
            "59/59 [==============================] - 26s 442ms/step - loss: 0.3301 - accuracy: 0.8944 - val_loss: 0.2325 - val_accuracy: 0.9032 - lr: 1.0000e-06\n",
            "Epoch 123/256\n",
            "59/59 [==============================] - 25s 429ms/step - loss: 0.3378 - accuracy: 0.8887 - val_loss: 0.2331 - val_accuracy: 0.9043 - lr: 1.0000e-06\n",
            "Epoch 124/256\n",
            "59/59 [==============================] - 26s 443ms/step - loss: 0.3323 - accuracy: 0.8930 - val_loss: 0.2319 - val_accuracy: 0.9043 - lr: 1.0000e-06\n",
            "Epoch 125/256\n",
            "59/59 [==============================] - 26s 442ms/step - loss: 0.3272 - accuracy: 0.8989 - val_loss: 0.2311 - val_accuracy: 0.9054 - lr: 1.0000e-06\n",
            "Epoch 126/256\n",
            "59/59 [==============================] - 26s 446ms/step - loss: 0.3319 - accuracy: 0.8970 - val_loss: 0.2304 - val_accuracy: 0.9032 - lr: 1.0000e-06\n",
            "Epoch 127/256\n",
            "59/59 [==============================] - 26s 441ms/step - loss: 0.3236 - accuracy: 0.9048 - val_loss: 0.2304 - val_accuracy: 0.9043 - lr: 1.0000e-06\n",
            "Epoch 128/256\n",
            "59/59 [==============================] - 26s 435ms/step - loss: 0.3331 - accuracy: 0.8909 - val_loss: 0.2305 - val_accuracy: 0.9032 - lr: 1.0000e-06\n",
            "Epoch 129/256\n",
            "59/59 [==============================] - 25s 429ms/step - loss: 0.3235 - accuracy: 0.9005 - val_loss: 0.2295 - val_accuracy: 0.9054 - lr: 1.0000e-06\n",
            "Epoch 130/256\n",
            "59/59 [==============================] - 25s 428ms/step - loss: 0.3274 - accuracy: 0.9000 - val_loss: 0.2288 - val_accuracy: 0.9054 - lr: 1.0000e-06\n",
            "Epoch 131/256\n",
            "59/59 [==============================] - 26s 441ms/step - loss: 0.3264 - accuracy: 0.9000 - val_loss: 0.2292 - val_accuracy: 0.9032 - lr: 1.0000e-06\n",
            "Epoch 132/256\n",
            "59/59 [==============================] - 26s 438ms/step - loss: 0.3262 - accuracy: 0.8968 - val_loss: 0.2292 - val_accuracy: 0.9032 - lr: 1.0000e-06\n",
            "Epoch 133/256\n",
            "59/59 [==============================] - 25s 426ms/step - loss: 0.3267 - accuracy: 0.8895 - val_loss: 0.2290 - val_accuracy: 0.9022 - lr: 1.0000e-06\n",
            "Epoch 134/256\n",
            "59/59 [==============================] - 26s 444ms/step - loss: 0.3182 - accuracy: 0.8965 - val_loss: 0.2282 - val_accuracy: 0.9011 - lr: 1.0000e-06\n",
            "Epoch 135/256\n",
            "59/59 [==============================] - 26s 441ms/step - loss: 0.3255 - accuracy: 0.8919 - val_loss: 0.2286 - val_accuracy: 0.9022 - lr: 1.0000e-06\n",
            "Epoch 136/256\n",
            "59/59 [==============================] - 26s 444ms/step - loss: 0.3214 - accuracy: 0.9013 - val_loss: 0.2279 - val_accuracy: 0.9032 - lr: 1.0000e-06\n",
            "Epoch 137/256\n",
            "59/59 [==============================] - 26s 444ms/step - loss: 0.3262 - accuracy: 0.9005 - val_loss: 0.2275 - val_accuracy: 0.9032 - lr: 1.0000e-06\n",
            "Epoch 138/256\n",
            "59/59 [==============================] - 26s 446ms/step - loss: 0.3265 - accuracy: 0.8984 - val_loss: 0.2272 - val_accuracy: 0.9022 - lr: 1.0000e-06\n",
            "Epoch 139/256\n",
            "59/59 [==============================] - 26s 442ms/step - loss: 0.3177 - accuracy: 0.9051 - val_loss: 0.2268 - val_accuracy: 0.9043 - lr: 1.0000e-06\n",
            "Epoch 140/256\n",
            "59/59 [==============================] - 26s 444ms/step - loss: 0.3106 - accuracy: 0.9175 - val_loss: 0.2262 - val_accuracy: 0.9043 - lr: 1.0000e-06\n",
            "Epoch 141/256\n",
            "59/59 [==============================] - 26s 444ms/step - loss: 0.3181 - accuracy: 0.9030 - val_loss: 0.2252 - val_accuracy: 0.9054 - lr: 1.0000e-06\n",
            "Epoch 142/256\n",
            "59/59 [==============================] - 25s 427ms/step - loss: 0.3111 - accuracy: 0.8992 - val_loss: 0.2251 - val_accuracy: 0.9065 - lr: 1.0000e-06\n",
            "Epoch 143/256\n",
            "59/59 [==============================] - 25s 429ms/step - loss: 0.3169 - accuracy: 0.9062 - val_loss: 0.2241 - val_accuracy: 0.9086 - lr: 1.0000e-06\n",
            "Epoch 144/256\n",
            "59/59 [==============================] - 26s 442ms/step - loss: 0.3222 - accuracy: 0.8981 - val_loss: 0.2245 - val_accuracy: 0.9075 - lr: 1.0000e-06\n",
            "Epoch 145/256\n",
            "59/59 [==============================] - 26s 437ms/step - loss: 0.3121 - accuracy: 0.9091 - val_loss: 0.2240 - val_accuracy: 0.9065 - lr: 1.0000e-06\n",
            "Epoch 146/256\n",
            "59/59 [==============================] - 25s 425ms/step - loss: 0.3014 - accuracy: 0.9094 - val_loss: 0.2245 - val_accuracy: 0.9065 - lr: 1.0000e-06\n",
            "Epoch 147/256\n",
            "59/59 [==============================] - 25s 430ms/step - loss: 0.3147 - accuracy: 0.9027 - val_loss: 0.2227 - val_accuracy: 0.9075 - lr: 1.0000e-06\n",
            "Epoch 148/256\n",
            "59/59 [==============================] - 26s 437ms/step - loss: 0.3147 - accuracy: 0.8987 - val_loss: 0.2221 - val_accuracy: 0.9086 - lr: 1.0000e-06\n",
            "Epoch 149/256\n",
            "59/59 [==============================] - 26s 438ms/step - loss: 0.3086 - accuracy: 0.9062 - val_loss: 0.2228 - val_accuracy: 0.9075 - lr: 1.0000e-06\n",
            "Epoch 150/256\n",
            "59/59 [==============================] - 26s 442ms/step - loss: 0.3071 - accuracy: 0.9067 - val_loss: 0.2231 - val_accuracy: 0.9118 - lr: 1.0000e-06\n",
            "Epoch 151/256\n",
            "59/59 [==============================] - 26s 439ms/step - loss: 0.3084 - accuracy: 0.9024 - val_loss: 0.2220 - val_accuracy: 0.9075 - lr: 1.0000e-06\n",
            "Epoch 152/256\n",
            "59/59 [==============================] - 25s 432ms/step - loss: 0.3072 - accuracy: 0.9075 - val_loss: 0.2225 - val_accuracy: 0.9097 - lr: 1.0000e-06\n",
            "Epoch 153/256\n",
            "59/59 [==============================] - 26s 445ms/step - loss: 0.3110 - accuracy: 0.9102 - val_loss: 0.2213 - val_accuracy: 0.9065 - lr: 1.0000e-06\n",
            "Epoch 154/256\n",
            "59/59 [==============================] - 26s 442ms/step - loss: 0.3064 - accuracy: 0.9083 - val_loss: 0.2213 - val_accuracy: 0.9075 - lr: 1.0000e-06\n",
            "Epoch 155/256\n",
            "59/59 [==============================] - 26s 446ms/step - loss: 0.3141 - accuracy: 0.9022 - val_loss: 0.2209 - val_accuracy: 0.9086 - lr: 1.0000e-06\n",
            "Epoch 156/256\n",
            "59/59 [==============================] - 31s 531ms/step - loss: 0.3086 - accuracy: 0.9116 - val_loss: 0.2202 - val_accuracy: 0.9065 - lr: 1.0000e-06\n",
            "Epoch 157/256\n",
            "59/59 [==============================] - 25s 425ms/step - loss: 0.3122 - accuracy: 0.9027 - val_loss: 0.2207 - val_accuracy: 0.9118 - lr: 1.0000e-06\n",
            "Epoch 158/256\n",
            "59/59 [==============================] - 26s 447ms/step - loss: 0.3100 - accuracy: 0.9046 - val_loss: 0.2195 - val_accuracy: 0.9097 - lr: 1.0000e-06\n",
            "Epoch 159/256\n",
            "59/59 [==============================] - 26s 438ms/step - loss: 0.3029 - accuracy: 0.9102 - val_loss: 0.2200 - val_accuracy: 0.9118 - lr: 1.0000e-06\n",
            "Epoch 160/256\n",
            "59/59 [==============================] - 25s 423ms/step - loss: 0.3114 - accuracy: 0.9083 - val_loss: 0.2204 - val_accuracy: 0.9118 - lr: 1.0000e-06\n",
            "Epoch 161/256\n",
            "59/59 [==============================] - 26s 441ms/step - loss: 0.3105 - accuracy: 0.9134 - val_loss: 0.2212 - val_accuracy: 0.9129 - lr: 1.0000e-06\n",
            "Epoch 162/256\n",
            "59/59 [==============================] - 26s 438ms/step - loss: 0.3084 - accuracy: 0.9070 - val_loss: 0.2191 - val_accuracy: 0.9118 - lr: 1.0000e-06\n",
            "Epoch 163/256\n",
            "59/59 [==============================] - 26s 441ms/step - loss: 0.3052 - accuracy: 0.9032 - val_loss: 0.2191 - val_accuracy: 0.9108 - lr: 1.0000e-06\n",
            "Epoch 164/256\n",
            "59/59 [==============================] - 26s 436ms/step - loss: 0.2982 - accuracy: 0.9121 - val_loss: 0.2206 - val_accuracy: 0.9118 - lr: 1.0000e-06\n",
            "Epoch 165/256\n",
            "59/59 [==============================] - 26s 434ms/step - loss: 0.2954 - accuracy: 0.9145 - val_loss: 0.2191 - val_accuracy: 0.9097 - lr: 1.0000e-06\n",
            "Epoch 166/256\n",
            "59/59 [==============================] - 26s 445ms/step - loss: 0.2984 - accuracy: 0.9142 - val_loss: 0.2186 - val_accuracy: 0.9097 - lr: 1.0000e-06\n",
            "Epoch 167/256\n",
            "59/59 [==============================] - 25s 423ms/step - loss: 0.2953 - accuracy: 0.9038 - val_loss: 0.2192 - val_accuracy: 0.9097 - lr: 1.0000e-06\n",
            "Epoch 168/256\n",
            "59/59 [==============================] - 26s 432ms/step - loss: 0.2950 - accuracy: 0.9153 - val_loss: 0.2177 - val_accuracy: 0.9108 - lr: 1.0000e-06\n",
            "Epoch 169/256\n",
            "59/59 [==============================] - 26s 440ms/step - loss: 0.2961 - accuracy: 0.9083 - val_loss: 0.2179 - val_accuracy: 0.9108 - lr: 1.0000e-06\n",
            "Epoch 170/256\n",
            "59/59 [==============================] - 26s 439ms/step - loss: 0.3068 - accuracy: 0.9083 - val_loss: 0.2179 - val_accuracy: 0.9108 - lr: 1.0000e-06\n",
            "Epoch 171/256\n",
            "59/59 [==============================] - 26s 443ms/step - loss: 0.3044 - accuracy: 0.9113 - val_loss: 0.2170 - val_accuracy: 0.9118 - lr: 1.0000e-06\n",
            "Epoch 172/256\n",
            "59/59 [==============================] - 25s 431ms/step - loss: 0.2980 - accuracy: 0.9118 - val_loss: 0.2167 - val_accuracy: 0.9097 - lr: 1.0000e-06\n",
            "Epoch 173/256\n",
            "59/59 [==============================] - 26s 446ms/step - loss: 0.2932 - accuracy: 0.9116 - val_loss: 0.2166 - val_accuracy: 0.9129 - lr: 1.0000e-06\n",
            "Epoch 174/256\n",
            "59/59 [==============================] - 26s 441ms/step - loss: 0.2960 - accuracy: 0.9151 - val_loss: 0.2167 - val_accuracy: 0.9108 - lr: 1.0000e-06\n",
            "Epoch 175/256\n",
            "59/59 [==============================] - 26s 443ms/step - loss: 0.3008 - accuracy: 0.9153 - val_loss: 0.2161 - val_accuracy: 0.9118 - lr: 1.0000e-06\n",
            "Epoch 176/256\n",
            "59/59 [==============================] - 26s 441ms/step - loss: 0.2941 - accuracy: 0.9151 - val_loss: 0.2166 - val_accuracy: 0.9129 - lr: 1.0000e-06\n",
            "Epoch 177/256\n",
            "59/59 [==============================] - 26s 445ms/step - loss: 0.3003 - accuracy: 0.9108 - val_loss: 0.2157 - val_accuracy: 0.9129 - lr: 1.0000e-06\n",
            "Epoch 178/256\n",
            "59/59 [==============================] - 25s 429ms/step - loss: 0.2903 - accuracy: 0.9234 - val_loss: 0.2155 - val_accuracy: 0.9140 - lr: 1.0000e-06\n",
            "Epoch 179/256\n",
            "59/59 [==============================] - 25s 426ms/step - loss: 0.2918 - accuracy: 0.9202 - val_loss: 0.2159 - val_accuracy: 0.9129 - lr: 1.0000e-06\n",
            "Epoch 180/256\n",
            "59/59 [==============================] - 26s 443ms/step - loss: 0.2926 - accuracy: 0.9151 - val_loss: 0.2149 - val_accuracy: 0.9129 - lr: 1.0000e-06\n",
            "Epoch 181/256\n",
            "59/59 [==============================] - 25s 425ms/step - loss: 0.2922 - accuracy: 0.9199 - val_loss: 0.2156 - val_accuracy: 0.9140 - lr: 1.0000e-06\n",
            "Epoch 182/256\n",
            "59/59 [==============================] - 25s 430ms/step - loss: 0.2867 - accuracy: 0.9188 - val_loss: 0.2145 - val_accuracy: 0.9129 - lr: 1.0000e-06\n",
            "Epoch 183/256\n",
            "59/59 [==============================] - 25s 423ms/step - loss: 0.2986 - accuracy: 0.9194 - val_loss: 0.2153 - val_accuracy: 0.9129 - lr: 1.0000e-06\n",
            "Epoch 184/256\n",
            "59/59 [==============================] - 31s 531ms/step - loss: 0.3019 - accuracy: 0.9097 - val_loss: 0.2155 - val_accuracy: 0.9129 - lr: 1.0000e-06\n",
            "Epoch 185/256\n",
            "59/59 [==============================] - 25s 422ms/step - loss: 0.2859 - accuracy: 0.9223 - val_loss: 0.2160 - val_accuracy: 0.9140 - lr: 1.0000e-06\n",
            "Epoch 186/256\n",
            "59/59 [==============================] - 25s 428ms/step - loss: 0.2886 - accuracy: 0.9185 - val_loss: 0.2150 - val_accuracy: 0.9118 - lr: 1.0000e-06\n",
            "Epoch 187/256\n",
            "59/59 [==============================] - 26s 440ms/step - loss: 0.2868 - accuracy: 0.9247 - val_loss: 0.2160 - val_accuracy: 0.9129 - lr: 1.0000e-06\n",
            "Epoch 188/256\n",
            "59/59 [==============================] - 26s 440ms/step - loss: 0.2741 - accuracy: 0.9218 - val_loss: 0.2152 - val_accuracy: 0.9140 - lr: 1.0000e-06\n",
            "Epoch 189/256\n",
            "59/59 [==============================] - 26s 446ms/step - loss: 0.2882 - accuracy: 0.9140 - val_loss: 0.2142 - val_accuracy: 0.9108 - lr: 1.0000e-06\n",
            "Epoch 190/256\n",
            "59/59 [==============================] - 25s 430ms/step - loss: 0.2833 - accuracy: 0.9191 - val_loss: 0.2154 - val_accuracy: 0.9140 - lr: 1.0000e-06\n",
            "Epoch 191/256\n",
            "59/59 [==============================] - 26s 439ms/step - loss: 0.2796 - accuracy: 0.9202 - val_loss: 0.2154 - val_accuracy: 0.9151 - lr: 1.0000e-06\n",
            "Epoch 192/256\n",
            "59/59 [==============================] - 25s 423ms/step - loss: 0.2813 - accuracy: 0.9228 - val_loss: 0.2152 - val_accuracy: 0.9118 - lr: 1.0000e-06\n",
            "Epoch 193/256\n",
            "59/59 [==============================] - 26s 439ms/step - loss: 0.2828 - accuracy: 0.9167 - val_loss: 0.2152 - val_accuracy: 0.9118 - lr: 1.0000e-06\n",
            "Epoch 194/256\n",
            "59/59 [==============================] - 25s 432ms/step - loss: 0.2867 - accuracy: 0.9237 - val_loss: 0.2147 - val_accuracy: 0.9118 - lr: 1.0000e-06\n",
            "Epoch 195/256\n",
            "59/59 [==============================] - 31s 527ms/step - loss: 0.2796 - accuracy: 0.9226 - val_loss: 0.2154 - val_accuracy: 0.9118 - lr: 1.0000e-06\n",
            "Epoch 196/256\n",
            "59/59 [==============================] - 26s 445ms/step - loss: 0.2832 - accuracy: 0.9183 - val_loss: 0.2148 - val_accuracy: 0.9108 - lr: 1.0000e-06\n"
          ]
        }
      ],
      "source": [
        "# Fine-tune the model with low learning rate\n",
        "convnet.compile(loss=tfk.losses.BinaryCrossentropy(), optimizer=tfk.optimizers.Adam(1e-6), metrics='accuracy')\n",
        "\n",
        "ft_history = convnet.fit(\n",
        "    train_ds_mu,\n",
        "    batch_size = 16,\n",
        "    epochs = 256,\n",
        "    validation_data = ((X_val), y_val),\n",
        "    callbacks = callbacks2,\n",
        ").history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v7C3R1MN8w8d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a128008b-6513-4713-ae42-0f5181131025"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set accuracy: 90.00%\n",
            "Test set precision: 90.07%\n",
            "Test set recall: 90.00%\n",
            "Test set F1: 90.03%\n"
          ]
        }
      ],
      "source": [
        "predicted_test = np.argmax(convnet.predict(X_test, verbose=\"silent\"), axis=-1)\n",
        "ground_truth_test = np.argmax(y_test, axis=-1)\n",
        "# Accuracy on test set\n",
        "accuracy_test = sklm.accuracy_score(ground_truth_test, predicted_test)\n",
        "print(f\"Test set accuracy: {accuracy_test:.2%}\")\n",
        "# Precision, recall, and F-score on test set.\n",
        "precision_test = sklm.precision_score(ground_truth_test, predicted_test, average=\"weighted\")\n",
        "recall_test = sklm.recall_score(ground_truth_test, predicted_test, average=\"weighted\")\n",
        "f_measure_test = sklm.f1_score(ground_truth_test, predicted_test, average=\"weighted\")\n",
        "print(f\"Test set precision: {precision_test:.2%}\")\n",
        "print(f\"Test set recall: {recall_test:.2%}\")\n",
        "print(f\"Test set F1: {f_measure_test:.2%}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pXo0831L8w8e"
      },
      "outputs": [],
      "source": [
        "convnet.save('SubmissionModel_ConvB_Final4_FT_1')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ConvNeXtLarge"
      ],
      "metadata": {
        "id": "k_OvFzGCFxsz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transfer Learning"
      ],
      "metadata": {
        "id": "VsA_z28qF369"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr_patience = 15\n",
        "lr_scheduler = tfk.callbacks.ReduceLROnPlateau(\n",
        "    monitor='val_accuracy',\n",
        "    patience=lr_patience,\n",
        "    factor=0.9,\n",
        "    mode='auto',\n",
        "    min_lr=1e-5\n",
        ")\n",
        "\n",
        "early_stopping = tfk.callbacks.EarlyStopping(monitor='val_accuracy', patience=20, restore_best_weights=True, mode='auto')\n",
        "\n",
        "callbacks = [\n",
        "    early_stopping,\n",
        "    lr_scheduler\n",
        "]"
      ],
      "metadata": {
        "id": "pA3pYZHMGnMP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "convnet = tf.keras.applications.ConvNeXtXLarge(\n",
        "    model_name=\"convnext_xlarge\",\n",
        "    include_top=False,\n",
        "    weights=\"imagenet\",\n",
        "    input_tensor=None,\n",
        "    input_shape=(96,96,3),\n",
        "    pooling=\"avg\",\n",
        "    classes=1000,\n",
        "    classifier_activation=\"softmax\",\n",
        "    include_preprocessing=True,\n",
        ")\n",
        "\n",
        "tfk.utils.plot_model(convnet, show_shapes=True)\n",
        "\n",
        "convnet.trainable = False\n",
        "\n",
        "l2_lambda = 2e-5\n",
        "\n",
        "inputs = tfk.Input(shape=(96, 96, 3))\n",
        "\n",
        "x = convnet(inputs)\n",
        "\n",
        "x = tfkl.Dense(units=64, activation='leaky_relu', kernel_initializer=tfk.initializers.HeUniform(seed=seed), kernel_regularizer=tf.keras.regularizers.l2(l2_lambda), name='classification4')(x)\n",
        "x = tfkl.Dropout(0.7, seed=seed)(x)\n",
        "\n",
        "# Add a Dense layer with 2 units and softmax activation as the classifier\n",
        "outputs = tfkl.Dense(2, activation='softmax')(x)\n",
        "\n",
        "# Create a Model connecting input and output\n",
        "convnet = tfk.Model(inputs=inputs, outputs=outputs, name='model')\n",
        "\n",
        "# Compile the model with Categorical Cross-Entropy loss and Adam optimizer\n",
        "convnet.compile(loss=tfk.losses.BinaryCrossentropy(), optimizer=tfk.optimizers.Adam(1e-4), metrics=['accuracy'])\n",
        "\n",
        "# Display model summary\n",
        "convnet.summary()\n"
      ],
      "metadata": {
        "id": "brsB83k7G3YH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tl_history = convnet.fit(\n",
        "    x = X_train,\n",
        "    y = y_train,\n",
        "    batch_size = 64,\n",
        "    epochs = 256,\n",
        "    validation_data = (X_val, y_val),\n",
        "    callbacks = callbacks\n",
        ").history"
      ],
      "metadata": {
        "id": "MlnH6rF4F8EW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "convnet.save(\"CN_L_TF\")\n",
        "predicted_test = np.argmax(convnet.predict(X_test, verbose=\"silent\"), axis=-1)\n",
        "ground_truth_test = np.argmax(y_test, axis=-1)\n",
        "# Accuracy on test set.\n",
        "accuracy_test = sklm.accuracy_score(ground_truth_test, predicted_test)\n",
        "print(f\"Test set accuracy: {accuracy_test:.2%}\")\n",
        "# Precision, recall, and F-score on test set.\n",
        "precision_test = sklm.precision_score(ground_truth_test, predicted_test, average=\"weighted\")\n",
        "recall_test = sklm.recall_score(ground_truth_test, predicted_test, average=\"weighted\")\n",
        "f_measure_test = sklm.f1_score(ground_truth_test, predicted_test, average=\"weighted\")\n",
        "print(f\"Test set precision: {precision_test:.2%}\")\n",
        "print(f\"Test set recall: {recall_test:.2%}\")\n",
        "print(f\"Test set F1: {f_measure_test:.2%}\")"
      ],
      "metadata": {
        "id": "kZOCK31VeqQX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fine Tuning"
      ],
      "metadata": {
        "id": "UKICdxKhG7qX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "convnet = tfk.models.load_model('CN_L_TF')\n",
        "convnet.get_layer('convnext_xlarge').trainable = True\n",
        "\n",
        "# Freeze first N layers\n",
        "N = 130\n",
        "for i, layer in enumerate(convnet.get_layer('convnext_xlarge').layers[:N]):\n",
        "  layer.trainable=False\n",
        "for i, layer in enumerate(convnet.get_layer('convnext_xlarge').layers):\n",
        "   print(i, layer.name, layer.trainable)\n",
        "convnet.summary()\n",
        "\n",
        "lr_patience = 7\n",
        "l2_lambda = 5e-5\n",
        "lr_scheduler = tfk.callbacks.ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    patience=lr_patience,\n",
        "    factor=0.9,\n",
        "    mode='min',\n",
        "    min_lr=1e-8\n",
        ")\n",
        "\n",
        "early_stopping = tfk.callbacks.EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True, mode='auto')\n",
        "\n",
        "callbacks2 = [\n",
        "    early_stopping,\n",
        "    lr_scheduler\n",
        "]\n",
        "\n",
        "convnet.compile(loss=tfk.losses.BinaryCrossentropy(), optimizer=tfk.optimizers.Adam(5e-6), metrics='accuracy')\n",
        "\n",
        "# Fine-tune the model\n",
        "ft_history = convnet.fit(\n",
        "    x = (X_train),\n",
        "    y = y_train,\n",
        "    batch_size = 32,\n",
        "    epochs = 500,\n",
        "    validation_data = (X_val, y_val),\n",
        "    callbacks = callbacks2\n",
        ").history"
      ],
      "metadata": {
        "id": "QWDAxba7HFQs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "convnet.save(\"CN_L_FT\")\n",
        "predicted_test = np.argmax(convnet.predict(X_test, verbose=\"silent\"), axis=-1)\n",
        "ground_truth_test = np.argmax(y_test, axis=-1)\n",
        "# Accuracy on test set.\n",
        "accuracy_test = sklm.accuracy_score(ground_truth_test, predicted_test)\n",
        "print(f\"Test set accuracy: {accuracy_test:.2%}\")\n",
        "# Precision, recall, and F-score on test set.\n",
        "precision_test = sklm.precision_score(ground_truth_test, predicted_test, average=\"weighted\")\n",
        "recall_test = sklm.recall_score(ground_truth_test, predicted_test, average=\"weighted\")\n",
        "f_measure_test = sklm.f1_score(ground_truth_test, predicted_test, average=\"weighted\")\n",
        "print(f\"Test set precision: {precision_test:.2%}\")\n",
        "print(f\"Test set recall: {recall_test:.2%}\")\n",
        "print(f\"Test set F1: {f_measure_test:.2%}\")"
      ],
      "metadata": {
        "id": "m3Edu_shfy6j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cross Validation"
      ],
      "metadata": {
        "id": "Fh4Z0Z2HkQ1t"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCJKiFFuxsUM"
      },
      "source": [
        "## EfficientNetV2L\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X2GZ0GX_ojnd"
      },
      "source": [
        "### K-Fold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V46LOUCsojne"
      },
      "outputs": [],
      "source": [
        "lr_patience = 15\n",
        "lr_scheduler = tfk.callbacks.ReduceLROnPlateau(\n",
        "    monitor='val_accuracy',\n",
        "    patience=lr_patience,\n",
        "    factor=0.9,\n",
        "    mode='auto',\n",
        "    min_lr=1e-5\n",
        ")\n",
        "\n",
        "early_stopping = tfk.callbacks.EarlyStopping(monitor='val_accuracy', patience=50, restore_best_weights=True, mode='auto')\n",
        "\n",
        "callbacks = [\n",
        "    early_stopping,\n",
        "    lr_scheduler\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bte1RpNQojne"
      },
      "outputs": [],
      "source": [
        "def build_model():\n",
        "  enet_model = tf.keras.applications.EfficientNetV2L(\n",
        "    include_top=False,\n",
        "    weights=\"imagenet\",\n",
        "    input_tensor=None,\n",
        "    input_shape=(96,96,3),\n",
        "    pooling=\"avg\",\n",
        "    classes=1000,\n",
        "    classifier_activation=\"softmax\",\n",
        "    include_preprocessing=True,\n",
        "  )\n",
        "\n",
        "  preprocessing = tf.keras.Sequential([\n",
        "          tfkl.RandomBrightness(0.2, value_range=(0,1)),\n",
        "          tfkl.RandomTranslation(0.2,0.2),\n",
        "          tfkl.RandomFlip(\"horizontal_and_vertical\"),\n",
        "          tfkl.RandomRotation(1),\n",
        "          tfkl.RandomZoom(0.2),\n",
        "      ], name='preprocessing')\n",
        "\n",
        "  tfk.utils.plot_model(enet_model, show_shapes=True)\n",
        "\n",
        "  enet_model.trainable = False\n",
        "\n",
        "  l2_lambda = 2e-5\n",
        "\n",
        "  inputs = tfk.Input(shape=(96, 96, 3))\n",
        "\n",
        "  inputs = preprocessing(inputs)\n",
        "\n",
        "  x = enet_model(inputs)\n",
        "\n",
        "  x = tfkl.Dense(units=1024, activation='relu',kernel_initializer=tfk.initializers.HeUniform(seed=seed), kernel_regularizer=tf.keras.regularizers.l2(l2_lambda), name='classification1')(x)\n",
        "  x = tfkl.Dropout(0.5, seed=seed)(x)\n",
        "\n",
        "  x = tfkl.Dense(units=512, activation='relu',kernel_initializer=tfk.initializers.HeUniform(seed=seed), kernel_regularizer=tf.keras.regularizers.l2(l2_lambda), name='classification2')(x)\n",
        "  x = tfkl.Dropout(0.5, seed=seed)(x)\n",
        "\n",
        "  x = tfkl.Dense(units=256, activation='relu', kernel_initializer=tfk.initializers.HeUniform(seed=seed), kernel_regularizer=tf.keras.regularizers.l2(l2_lambda), name='classification3')(x)\n",
        "  x = tfkl.Dropout(0.5, seed=seed)(x)\n",
        "\n",
        "  x = tfkl.Dense(units=128, activation='relu', kernel_initializer=tfk.initializers.HeUniform(seed=seed), kernel_regularizer=tf.keras.regularizers.l2(l2_lambda), name='classification4')(x)\n",
        "  x = tfkl.Dropout(0.5, seed=seed)(x)\n",
        "\n",
        "  outputs = tfkl.Dense(2, activation='softmax')(x)\n",
        "\n",
        "  enet_model = tfk.Model(inputs=inputs, outputs=outputs, name='model')\n",
        "\n",
        "  enet_model.compile(loss=tfk.losses.BinaryCrossentropy(), optimizer=tfk.optimizers.Adam(), metrics=['accuracy'])\n",
        "\n",
        "  # Return the model\n",
        "  return enet_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HVvnD8jkojnf"
      },
      "outputs": [],
      "source": [
        "# Define the number of folds for cross-validation\n",
        "num_folds = 5\n",
        "# Initialize lists to store training histories, scores, and best epochs\n",
        "histories = []\n",
        "scores = []\n",
        "best_epochs = []\n",
        "\n",
        "# Create a KFold cross-validation object\n",
        "kfold = KFold(n_splits=num_folds, shuffle=True, random_state=seed)\n",
        "\n",
        "# Loop through each fold\n",
        "for fold_idx, (train_idx, valid_idx) in enumerate(kfold.split(X_train_val, y_train_val)):\n",
        "\n",
        "  print(\"Starting training on fold num: {}\".format(fold_idx+1))\n",
        "\n",
        "  # Build a new dropout model for each fold\n",
        "  k_model = build_model()\n",
        "\n",
        "  # Train the model on the training data for this fold\n",
        "  history = k_model.fit(\n",
        "    x = tf.keras.applications.efficientnet_v2.preprocess_input(X_train_val[train_idx]*255),\n",
        "    y = y_train_val[train_idx],\n",
        "    validation_data=(tf.keras.applications.efficientnet_v2.preprocess_input(X_train_val[valid_idx]*255), y_train_val[valid_idx]),\n",
        "    batch_size = 256,\n",
        "    epochs = 1000,\n",
        "    callbacks = callbacks,\n",
        "  ).history\n",
        "\n",
        "  # Evaluate the model on the validation data for this fold\n",
        "  score = k_model.evaluate(X_train_val[valid_idx]*255, y_train_val[valid_idx], verbose=0)\n",
        "  scores.append(score[1])\n",
        "\n",
        "  # Calculate the best epoch for early stopping\n",
        "  best_epoch = len(history['loss']) - 50\n",
        "  best_epochs.append(best_epoch)\n",
        "\n",
        "  # Store the training history for this fold\n",
        "  histories.append(history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1DvpJRbIojng"
      },
      "outputs": [],
      "source": [
        "# Calculate the average best epoch\n",
        "avg_epochs = int(np.mean(best_epochs))\n",
        "print(f\"Best average epoch: {avg_epochs}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pSJklf0aojng"
      },
      "outputs": [],
      "source": [
        "# Build the final model using the calculated average best epoch\n",
        "final_model = build_model()\n",
        "\n",
        "# Train the final model on the combined training and validation data\n",
        "final_history = final_model.fit(\n",
        "    x = tf.keras.applications.mobilenet_v3.preprocess_input(X_train_val*255),\n",
        "    y = y_train_val,\n",
        "    batch_size = 256,\n",
        "    epochs = avg_epochs\n",
        ").history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hwou4Mfrojnh"
      },
      "outputs": [],
      "source": [
        "model = final_model\n",
        "\n",
        "final_model.save('SubmissionModel')\n",
        "\n",
        "predicted_test = np.argmax(model.predict(X_test*255, verbose=\"silent\"), axis=-1)\n",
        "ground_truth_test = np.argmax(y_test, axis=-1)\n",
        "# Accuracy on test set.\n",
        "accuracy_test = sklm.accuracy_score(ground_truth_test, predicted_test)\n",
        "print(f\"Test set accuracy: {accuracy_test:.2%}\")\n",
        " #Precision, recall, and F-score on test set.\n",
        "precision_test = sklm.precision_score(ground_truth_test, predicted_test, average=\"weighted\")\n",
        "recall_test = sklm.recall_score(ground_truth_test, predicted_test, average=\"weighted\")\n",
        "f_measure_test = sklm.f1_score(ground_truth_test, predicted_test, average=\"weighted\")\n",
        "print(f\"Test set precision: {precision_test:.2%}\")\n",
        "print(f\"Test set recall: {recall_test:.2%}\")\n",
        "print(f\"Test set F1: {f_measure_test:.2%}\")\n",
        "enet_model = final_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUBpVmRZhXsl"
      },
      "source": [
        "## MobileNetV3Small"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U85NSfZxsBi6"
      },
      "source": [
        "### K-Fold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jJJXzM9PxBSv"
      },
      "outputs": [],
      "source": [
        "lr_patience = 15\n",
        "lr_scheduler = tfk.callbacks.ReduceLROnPlateau(\n",
        "    monitor='val_accuracy',\n",
        "    patience=lr_patience,\n",
        "    factor=0.9,\n",
        "    mode='auto',\n",
        "    min_lr=1e-5\n",
        ")\n",
        "\n",
        "early_stopping = tfk.callbacks.EarlyStopping(monitor='val_accuracy', patience=50, restore_best_weights=True, mode='auto')\n",
        "\n",
        "callbacks = [\n",
        "    early_stopping,\n",
        "    lr_scheduler\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ELb8icysUng"
      },
      "outputs": [],
      "source": [
        "def build_model():\n",
        "\n",
        "    enet_model = tf.keras.applications.MobileNetV3Small(\n",
        "    input_shape=(96,96,3),\n",
        "    alpha=1.0,\n",
        "    minimalistic=False,\n",
        "    include_top=False,\n",
        "    weights=\"imagenet\",\n",
        "    input_tensor=None,\n",
        "    classes=1000,\n",
        "    pooling='avg',\n",
        "    dropout_rate=0.2,\n",
        "    classifier_activation=\"softmax\",\n",
        "    include_preprocessing=True,\n",
        "    )\n",
        "\n",
        "    preprocessing = tf.keras.Sequential([\n",
        "            tfkl.RandomFlip(\"horizontal_and_vertical\"),\n",
        "            tfkl.RandomZoom(0.2),\n",
        "        ], name='preprocessing')\n",
        "\n",
        "    tfk.utils.plot_model(enet_model, show_shapes=True)\n",
        "\n",
        "    enet_model.trainable = False\n",
        "\n",
        "    l2_lambda = 2e-4\n",
        "\n",
        "    inputs = tfk.Input(shape=(96, 96, 3))\n",
        "\n",
        "    inputs = preprocessing(inputs)\n",
        "\n",
        "    x = enet_model(inputs)\n",
        "\n",
        "    x = tfkl.Dense(units=576, activation='relu',kernel_initializer=tfk.initializers.HeUniform(seed=seed), kernel_regularizer=tf.keras.regularizers.l2(l2_lambda), name='classification2')(x)\n",
        "    x = tfkl.Dropout(0.5, seed=seed)(x)\n",
        "\n",
        "    x = tfkl.Dense(units=256, activation='relu', kernel_initializer=tfk.initializers.HeUniform(seed=seed), kernel_regularizer=tf.keras.regularizers.l2(l2_lambda), name='classification3')(x)\n",
        "    x = tfkl.Dropout(0.5, seed=seed)(x)\n",
        "\n",
        "    # Add a Dense layer with 2 units and softmax activation as the classifier\n",
        "    outputs = tfkl.Dense(2, activation='softmax')(x)\n",
        "\n",
        "    # Create a Model connecting input and output\n",
        "    enet_model = tfk.Model(inputs=inputs, outputs=outputs, name='model')\n",
        "\n",
        "    # Compile the model with Categorical Cross-Entropy loss and Adam optimizer\n",
        "    enet_model.compile(loss=tfk.losses.BinaryCrossentropy(), optimizer=tfk.optimizers.Adam(learning_rate = 1e-4), metrics=['accuracy'])\n",
        "\n",
        "    # Return the model\n",
        "    return enet_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gmAf4doxsExx"
      },
      "outputs": [],
      "source": [
        "# Define the number of folds for cross-validation\n",
        "num_folds = 10\n",
        "\n",
        "# Initialize lists to store training histories, scores, and best epochs\n",
        "histories = []\n",
        "scores = []\n",
        "best_epochs = []\n",
        "\n",
        "# Create a KFold cross-validation object\n",
        "kfold = KFold(n_splits=num_folds, shuffle=True, random_state=seed)\n",
        "\n",
        "# Loop through each fold\n",
        "for fold_idx, (train_idx, valid_idx) in enumerate(kfold.split(X_train_val, y_train_val)):\n",
        "\n",
        "  print(\"Starting training on fold num: {}\".format(fold_idx+1))\n",
        "\n",
        "  # Build a new dropout model for each fold\n",
        "  k_model = build_model()\n",
        "\n",
        "  # Train the model on the training data for this fold\n",
        "  history = k_model.fit(\n",
        "    x = tf.keras.applications.mobilenet_v3.preprocess_input(X_train_val[train_idx]*255),\n",
        "    y = y_train_val[train_idx],\n",
        "    validation_data=(tf.keras.applications.mobilenet_v3.preprocess_input (X_train_val[valid_idx]*255), y_train_val[valid_idx]),\n",
        "    batch_size = 128,\n",
        "    epochs = 1000,\n",
        "    callbacks = callbacks,\n",
        "  ).history\n",
        "\n",
        "  # Evaluate the model on the validation data for this fold\n",
        "  score = k_model.evaluate(X_train_val[valid_idx]*255, y_train_val[valid_idx], verbose=0)\n",
        "  scores.append(score[1])\n",
        "\n",
        "  # Calculate the best epoch for early stopping\n",
        "  best_epoch = len(history['loss']) - 50\n",
        "  best_epochs.append(best_epoch)\n",
        "\n",
        "  # Store the training history for this fold\n",
        "  histories.append(history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dOzASrhSs45T"
      },
      "outputs": [],
      "source": [
        "# Calculate the average best epoch\n",
        "avg_epochs = int(np.mean(best_epochs))\n",
        "print(f\"Best average epoch: {avg_epochs}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b2StFrdms8HC"
      },
      "outputs": [],
      "source": [
        "# Build the final model using the calculated average best epoch\n",
        "final_model = build_model()\n",
        "\n",
        "# Train the final model on the combined training and validation data\n",
        "final_history = final_model.fit(\n",
        "    x = tf.keras.applications.mobilenet_v3.preprocess_input(X_train_val*255),\n",
        "    y = y_train_val,\n",
        "    batch_size = 256,\n",
        "    epochs = avg_epochs\n",
        ").history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iI_iCeK01wPM"
      },
      "outputs": [],
      "source": [
        "model = final_model\n",
        "\n",
        "final_model.save('SubmissionModel')\n",
        "\n",
        "predicted_test = np.argmax(model.predict(X_test*255, verbose=\"silent\"), axis=-1)\n",
        "ground_truth_test = np.argmax(y_test, axis=-1)\n",
        "# Accuracy on test set.\n",
        "accuracy_test = sklm.accuracy_score(ground_truth_test, predicted_test)\n",
        "print(f\"Test set accuracy: {accuracy_test:.2%}\")\n",
        " #Precision, recall, and F-score on test set.\n",
        "precision_test = sklm.precision_score(ground_truth_test, predicted_test, average=\"weighted\")\n",
        "recall_test = sklm.recall_score(ground_truth_test, predicted_test, average=\"weighted\")\n",
        "f_measure_test = sklm.f1_score(ground_truth_test, predicted_test, average=\"weighted\")\n",
        "print(f\"Test set precision: {precision_test:.2%}\")\n",
        "print(f\"Test set recall: {recall_test:.2%}\")\n",
        "print(f\"Test set F1: {f_measure_test:.2%}\")\n",
        "enet_model = final_model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ensemble Test"
      ],
      "metadata": {
        "id": "0t77pihUH-gr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple ensemble with majority voting\n",
        "model1 = tf.keras.models.load_model('ConvNeXtBase_1')\n",
        "model2 = tf.keras.models.load_model('ConvNeXtBase_2')\n",
        "model3 = tf.keras.models.load_model('ConvNeXtXLarge')\n",
        "\n",
        "predicted_test1= np.argmax(model1.predict(X_test, verbose=\"silent\"), axis=-1)\n",
        "predicted_test2 = np.argmax(model2.predict(X_test, verbose=\"silent\"), axis=-1)\n",
        "predicted_test3 = np.argmax(model3.predict(X_test, verbose=\"silent\"), axis=-1)\n",
        "\n",
        "predicted_test = predicted_test1 +predicted_test2 + predicted_test3\n",
        "\n",
        "predicted_test = (predicted_test>= 2)\n",
        "ground_truth_test = np.argmax(y_test, axis=-1)\n",
        "\n",
        "accuracy_test = sklm.accuracy_score(ground_truth_test, predicted_test)\n",
        "print(f\"Test set accuracy: {accuracy_test:.2%}\")\n",
        "\n",
        "precision_test = sklm.precision_score(ground_truth_test, predicted_test, average=\"weighted\")\n",
        "recall_test = sklm.recall_score(ground_truth_test, predicted_test, average=\"weighted\")\n",
        "f_measure_test = sklm.f1_score(ground_truth_test, predicted_test, average=\"weighted\")\n",
        "print(f\"Test set precision: {precision_test:.2%}\")\n",
        "print(f\"Test set recall: {recall_test:.2%}\")\n",
        "print(f\"Test set F1: {f_measure_test:.2%}\")"
      ],
      "metadata": {
        "id": "s-vI5-U5IA3M"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}